{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10af6d3",
   "metadata": {},
   "source": [
    "# Pointwise Classification\n",
    "\n",
    "In this notebook, we examine the pointwise classification approach, including tuning and trying different estimators. First, we load the required dependencies and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71e47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pandas as pd\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from datetime import timedelta\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from time import time\n",
    "\n",
    "from src import configuration as config\n",
    "from src.pipeline.pipeline_factory import PipelineFactory, ModelType, EvaluationType\n",
    "from src.pipeline.pipeline_transformers import *\n",
    "\n",
    "\n",
    "# load the data\n",
    "train_df = config.load_traindata_for_pointwise()\n",
    "pipelineFactory = PipelineFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e1d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  tuning  scoring  rank\n",
      "DTC    full    ACC      0.0     135\n",
      "                        1.0      71\n",
      "                        2.0      50\n",
      "                        3.0      43\n",
      "                        5.0      39\n",
      "                               ... \n",
      "SVC    no      F1       27.0      9\n",
      "                        28.0      7\n",
      "                        29.0      6\n",
      "                        30.0      5\n",
      "                        31.0      2\n",
      "Name: count, Length: 1146, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# group by the columns: model, tuning, scoring\n",
    "# for each group print out the unique values of the rank column\n",
    "grouped_df = train_df.groupby([\"model\", \"tuning\", \"scoring\"])[\"rank\"].value_counts()\n",
    "print(grouped_df)\n",
    "# save the grouped dataframe to a csv file\n",
    "path = os.path.join(config.FIGURE_DIR, \"pointwise_ranking.csv\")\n",
    "grouped_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cc673",
   "metadata": {},
   "source": [
    "## Pointwise Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5df4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pipeline ...\n",
      "{'keeper': ColumnKeeper(columns=['dataset', 'model', 'tuning', 'scoring', 'encoder']), 'encoder_transformer': PoincareEmbedding(batch_size=50, encoder=OneHotEncoder(), epochs=500,\n",
      "                  graph=<networkx.classes.graph.Graph object at 0x00000216B2600C40>,\n",
      "                  size=3), 'dataset_transformer': OpenMLMetaFeatureTransformer(encoder=None, expected_pca_variance=0.6,\n",
      "                             nan_ratio_feature_drop_threshold=0.25), 'general_transformer': GeneralPurposeEncoderTransformer(model_encoder=OneHotEncoder(),\n",
      "                                 scoring_encoder=TargetEncoder(),\n",
      "                                 tuning_encoder=TargetEncoder()), 'estimator': DecisionTreeClassifier()}\n",
      "Starting pipeline using method: EvaluationType.CROSS_VALIDATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:46<00:00,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running the pipeline\n",
      "Evaluation metrics:\n",
      "    validation_average_spearman_fold_0: 0.6486\n",
      "    validation_average_spearman_fold_1: 0.6103\n",
      "    validation_average_spearman_fold_2: 0.6211\n",
      "    validation_average_spearman_fold_3: 0.6254\n",
      "    validation_average_spearman_fold_4: 0.636\n",
      "    average of all folds: 0.6283 [std=0.0131]\n",
      "\n",
      "runtime: 0:00:54 [54s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "# running the pipeline plain wihout parameter tuning using cross validation\n",
    "pipeline = pipelineFactory.create_pipeline(\n",
    "    train_df,\n",
    "    ModelType.POINTWISE_CLASSIFICATION_NO_SEARCH,\n",
    "    evaluation=EvaluationType.CROSS_VALIDATION,\n",
    "    verbose_level=1,\n",
    "    n_folds=5,\n",
    "    workers=16,\n",
    "    target=\"rank\"\n",
    ")\n",
    "\n",
    "#pipeline.add_new_step(PrintDataframe(verbose=1), \"print_dataframe_1\")\n",
    "print(pipeline.get_pipeline().named_steps)\n",
    "pipeline.run()\n",
    "\n",
    "runtime = int(time() - start)\n",
    "print('\\nruntime: ' + str(timedelta(seconds=runtime)) + ' [' + str(runtime) + 's]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284b496",
   "metadata": {},
   "source": [
    "### Tuning with Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1babf4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pipeline ...\n",
      "Starting pipeline using method: EvaluationType.BAYES_SEARCH\n",
      "Performing bayes search\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "best score: 0.28449099814212225\n",
      "best params:\n",
      "    dataset_transformer__encoder: None\n",
      "    dataset_transformer__expected_pca_variance: 1.0\n",
      "    dataset_transformer__nan_ratio_feature_drop_threshold: 0.5\n",
      "    encoder_transformer__encoder: OneHotEncoder()\n",
      "    estimator__max_depth: 50\n",
      "    estimator__max_features: None\n",
      "    estimator__min_samples_leaf: 1\n",
      "    estimator__min_samples_split: 2\n",
      "    general_transformer__model_encoder: OneHotEncoder()\n",
      "    general_transformer__scoring_encoder: OrdinalEncoder()\n",
      "    general_transformer__tuning_encoder: OneHotEncoder()\n",
      "Training pipeline with best parameters...\n",
      "Evaluating pipeline with best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:50<00:00, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running the pipeline\n",
      "Evaluation metrics:\n",
      "    validation_average_spearman_fold_0: 0.6463 [std=0.]\n",
      "    validation_average_spearman_fold_1: 0.6021 [std=0.]\n",
      "    validation_average_spearman_fold_2: 0.6093 [std=0.]\n",
      "    validation_average_spearman_fold_3: 0.6285 [std=0.]\n",
      "    validation_average_spearman_fold_4: 0.6012 [std=0.]\n",
      "    average_spearman (5-fold): 0.6175 [std=0.0174]\n",
      "\n",
      "runtime: 1:24:25 [5065s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "# number of optimization rounds = n_iter / n_points (e.g. 50 rounds in our case)\n",
    "n_iter = 200 # how many unique parameters to examine - our default: 200\n",
    "n_points = 4 # how many unique parameter combinations per optimization round - our default: 4\n",
    "cv = 4 # how many fits for each unique parameter combination - our default: 4\n",
    "n_jobs = -1 # how many fits in parallel (only parallelizable per round) - our default: -1\n",
    "\n",
    "pipeline = pipelineFactory.create_pipeline(\n",
    "    train_df,\n",
    "    ModelType.POINTWISE_CLASSIFICATION_BAYES_SEARCH,\n",
    "    verbose_level=1,\n",
    "    target=\"rank\",\n",
    "    bayes_n_iter=n_iter,\n",
    "    bayes_n_points=n_points,\n",
    "    bayes_cv=cv,\n",
    "    bayes_n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "pipeline.run()\n",
    "\n",
    "runtime = int(time() - start)\n",
    "print('\\nruntime: ' + str(timedelta(seconds=runtime)) + ' [' + str(runtime) + 's]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e59a0",
   "metadata": {},
   "source": [
    "## Runtime on Server Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c329ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pandas as pd\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from datetime import timedelta\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from time import time\n",
    "\n",
    "from src import configuration as config\n",
    "from src.pipeline.pipeline_factory import PipelineFactory, ModelType, EvaluationType\n",
    "from src.pipeline.pipeline_transformers import *\n",
    "\n",
    "train_df = config.load_traindata_for_pointwise()\n",
    "pipelineFactory = PipelineFactory()\n",
    "\n",
    "start = time()\n",
    "\n",
    "# running the pipeline plain wihout parameter tuning using cross validation\n",
    "pipeline = pipelineFactory.create_pipeline(\n",
    "    train_df,\n",
    "    ModelType.POINTWISE_CLASSIFICATION_NO_SEARCH,\n",
    "    evaluation=EvaluationType.CROSS_VALIDATION,\n",
    "    verbose_level=1,\n",
    "    n_folds=5,\n",
    "    workers=16,\n",
    "    target=\"rank\"\n",
    ")\n",
    "pipeline.run()\n",
    "\n",
    "runtime = int(time() - start)\n",
    "print('\\nruntime: ' + str(timedelta(seconds=runtime)) + ' [' + str(runtime) + 's]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadbecd",
   "metadata": {},
   "source": [
    "```\n",
    "Creating pipeline ...\n",
    "Starting pipeline using method: EvaluationType.CROSS_VALIDATION\n",
    "Finished running the pipeline\n",
    "Evaluation metrics:\n",
    "    validation_average_spearman_fold_0: 0.6354\n",
    "    validation_average_spearman_fold_1: 0.6061\n",
    "    validation_average_spearman_fold_2: 0.618\n",
    "    validation_average_spearman_fold_3: 0.6298\n",
    "    validation_average_spearman_fold_4: 0.6323\n",
    "    average of all folds: 0.6243 [std=0.0108]\n",
    "\n",
    "runtime: 0:00:51 [51s]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
