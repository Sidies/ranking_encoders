{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Graph Embeddings\n",
    "The purpose of this notebook is to apply graph embeddings in our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from src import configuration as config\n",
    "from src.pipeline.pipeline_factory import PipelineFactory, ModelType, EvaluationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline using method: EvaluationType.BASIC\n",
      "0.0\n",
      "Finished running the pipeline\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "train_df = config.load_traindata_for_regression()\n",
    "pipelineFactory = PipelineFactory()\n",
    "\n",
    "# create the baseline pipeline\n",
    "pipeline = pipelineFactory.create_pipeline(train_df,\n",
    "                                            ModelType.REGRE_BASELINE,\n",
    "                                            verbose_level=1,\n",
    "                                            evaluation=EvaluationType.BASIC)\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.encoder_utils import load_graph\n",
    "graph = load_graph(config.ROOT_DIR / \"data/external/graphs/encodings_graph.adjlist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embeddings_transformer': Node2VecEmbedding(graph=<networkx.classes.graph.Graph object at 0x0000018D1BC4D7D0>), 'print_df_1': PrintDataframe(verbose=1), 'column_keeper': ColumnKeeper(columns=['node2vec_embedding_dim1', 'node2vec_embedding_dim2']), 'print_df_2': PrintDataframe(verbose=1), 'estimator': DummyRegressor()}\n",
      "Starting pipeline using method: EvaluationType.BASIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 45/45 [00:00<00:00, 2180.57it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1000/1000 [00:10<00:00, 96.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  node2vec_embedding_dim1  \\\n",
      "0    23381    LR  model      F1            BE                 0.085825   \n",
      "1    23381    LR  model      F1  BUCV10RGLMME                -0.073088   \n",
      "2    23381    LR  model      F1      BUCV10TE                 0.195790   \n",
      "3    23381    LR  model      F1   BUCV2RGLMME                -0.063628   \n",
      "4    23381    LR  model      F1       BUCV2TE                 0.224964   \n",
      "\n",
      "   node2vec_embedding_dim2  \n",
      "0                -0.219572  \n",
      "1                -0.119526  \n",
      "2                -0.281009  \n",
      "3                -0.220700  \n",
      "4                -0.329527  \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   node2vec_embedding_dim1  node2vec_embedding_dim2\n",
      "0                 0.085825                -0.219572\n",
      "1                -0.073088                -0.119526\n",
      "2                 0.195790                -0.281009\n",
      "3                -0.063628                -0.220700\n",
      "4                 0.224964                -0.329527\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 45/45 [00:00<00:00, 2874.69it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1000/1000 [00:09<00:00, 107.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  node2vec_embedding_dim1  \\\n",
      "0    41007   SVC     no     ACC            BE                -0.072245   \n",
      "1    41007   SVC     no     ACC  BUCV10RGLMME                 0.198608   \n",
      "2    41007   SVC     no     ACC      BUCV10TE                 0.240993   \n",
      "3    41007   SVC     no     ACC   BUCV2RGLMME                 0.170766   \n",
      "4    41007   SVC     no     ACC       BUCV2TE                 0.282515   \n",
      "\n",
      "   node2vec_embedding_dim2  \n",
      "0                -0.106322  \n",
      "1                 0.015082  \n",
      "2                 0.032120  \n",
      "3                 0.050684  \n",
      "4                 0.021936  \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   node2vec_embedding_dim1  node2vec_embedding_dim2\n",
      "0                -0.072245                -0.106322\n",
      "1                 0.198608                 0.015082\n",
      "2                 0.240993                 0.032120\n",
      "3                 0.170766                 0.050684\n",
      "4                 0.282515                 0.021936\n",
      "----------------------------------------\n",
      "0.0\n",
      "Finished running the pipeline\n"
     ]
    }
   ],
   "source": [
    "pipeline.clear_steps()\n",
    "from src.pipeline.pipeline_transformers import Node2VecEmbedding, PrintDataframe, ColumnKeeper\n",
    "n2v_embedddings_transformer = Node2VecEmbedding(graph=graph, walk_length=20, num_walks=1000, workers=1)\n",
    "\n",
    "# add the column transformer to the pipeline\n",
    "pipeline.add_new_step(n2v_embedddings_transformer, \"embeddings_transformer\")\n",
    "\n",
    "pipeline.add_new_step(PrintDataframe(verbose=pipeline._verbose_level), \"print_df_1\")\n",
    "\n",
    "pipeline.add_new_step(ColumnKeeper(columns=[\"node2vec_embedding_dim1\", \"node2vec_embedding_dim2\"]),\n",
    "                                  \"column_keeper\")\n",
    "\n",
    "pipeline.add_new_step(PrintDataframe(verbose=pipeline._verbose_level), \"print_df_2\")\n",
    "\n",
    "print(pipeline.get_pipeline().named_steps)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out Node2Vec with kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embeddings_transformer': Node2VecGraphEmbeddingWithKMeans(graph=<networkx.classes.graph.Graph object at 0x0000018D1BC4D7D0>), 'estimator': DummyRegressor()}\n"
     ]
    }
   ],
   "source": [
    "pipeline.clear_steps()\n",
    "from src.pipeline.pipeline_transformers import Node2VecGraphEmbeddingWithKMeans\n",
    "\n",
    "n2v_embedddings_transformer = Node2VecGraphEmbeddingWithKMeans(graph=graph)\n",
    "\n",
    "# add the column transformer to the pipeline\n",
    "pipeline.add_new_step(n2v_embedddings_transformer, \"embeddings_transformer\")\n",
    "\n",
    "print(pipeline.get_pipeline().named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embeddings_transformer': Node2VecGraphEmbeddingWithKMeans(graph=<networkx.classes.graph.Graph object at 0x0000018D1BC4D7D0>), 'print_df': PrintDataframe(verbose=1), 'estimator': DummyRegressor()}\n",
      "Starting pipeline using method: EvaluationType.BASIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 45/45 [00:00<00:00, 2877.72it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 19.94it/s]\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  encoder_cluster\n",
      "0    23381    LR  model      F1            BE                2\n",
      "1    23381    LR  model      F1  BUCV10RGLMME                3\n",
      "2    23381    LR  model      F1      BUCV10TE                0\n",
      "3    23381    LR  model      F1   BUCV2RGLMME                3\n",
      "4    23381    LR  model      F1       BUCV2TE                0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 45/45 [00:00<00:00, 2004.48it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 24.74it/s]\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  encoder_cluster\n",
      "0    41007   SVC     no     ACC            BE                1\n",
      "1    41007   SVC     no     ACC  BUCV10RGLMME                2\n",
      "2    41007   SVC     no     ACC      BUCV10TE                4\n",
      "3    41007   SVC     no     ACC   BUCV2RGLMME                2\n",
      "4    41007   SVC     no     ACC       BUCV2TE                4\n",
      "----------------------------------------\n",
      "0.0\n",
      "Finished running the pipeline\n"
     ]
    }
   ],
   "source": [
    "# check if the embedding worked\n",
    "from src.pipeline.pipeline_transformers import PrintDataframe\n",
    "pipeline.add_new_step(PrintDataframe(verbose=pipeline._verbose_level), \"print_df\")\n",
    "print(pipeline.get_pipeline().named_steps)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the application of the kmeans encoder worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embeddings_transformer': Node2VecGraphEmbeddingWithKMeans(graph=<networkx.classes.graph.Graph object at 0x0000018D1BC4D7D0>), 'print_df': PrintDataframe(verbose=1), 'column_keeper': ColumnKeeper(columns=['encoder_cluster']), 'print_df_2': PrintDataframe(verbose=1), 'estimator': LinearRegression()}\n",
      "Starting pipeline using method: EvaluationType.BASIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 45/45 [00:00<00:00, 2882.73it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 23.42it/s]\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  encoder_cluster\n",
      "0    23381    LR  model      F1            BE                4\n",
      "1    23381    LR  model      F1  BUCV10RGLMME                2\n",
      "2    23381    LR  model      F1      BUCV10TE                1\n",
      "3    23381    LR  model      F1   BUCV2RGLMME                2\n",
      "4    23381    LR  model      F1       BUCV2TE                1\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   encoder_cluster\n",
      "0                4\n",
      "1                2\n",
      "2                1\n",
      "3                2\n",
      "4                1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 45/45 [00:00<00:00, 5021.51it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 24.81it/s]\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  encoder_cluster\n",
      "0    41007   SVC     no     ACC            BE                1\n",
      "1    41007   SVC     no     ACC  BUCV10RGLMME                2\n",
      "2    41007   SVC     no     ACC      BUCV10TE                5\n",
      "3    41007   SVC     no     ACC   BUCV2RGLMME                2\n",
      "4    41007   SVC     no     ACC       BUCV2TE                5\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   encoder_cluster\n",
      "0                1\n",
      "1                2\n",
      "2                5\n",
      "3                2\n",
      "4                5\n",
      "----------------------------------------\n",
      "-0.04293566411797524\n",
      "Finished running the pipeline\n"
     ]
    }
   ],
   "source": [
    "# lets try to get a prediction with a regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from src.pipeline.pipeline_transformers import ColumnKeeper\n",
    "\n",
    "# only keep selected columns\n",
    "column_keeper = ColumnKeeper(columns=[\"encoder_cluster\"])\n",
    "\n",
    "pipeline.add_new_step(column_keeper, \"column_keeper\")\n",
    "pipeline.add_new_step(PrintDataframe(verbose=pipeline._verbose_level), \"print_df_2\")\n",
    "\n",
    "pipeline.change_estimator(LinearRegression())\n",
    "\n",
    "print(pipeline.get_pipeline().named_steps)\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test run the pipeline score is a 0.015. As we are using spearmans R as our metric where the best score is 1.0 or -1.0 we can see that we achieved a very poor score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embeddings_transformer': PoincareEmbedding(graph=<networkx.classes.graph.Graph object at 0x0000018D1BC4D7D0>), 'print_df_1': PrintDataframe(verbose=1), 'column_keeper': ColumnKeeper(columns=['poincare_embedding_dim1', 'poincare_embedding_dim2']), 'print_df_2': PrintDataframe(verbose=1), 'estimator': LinearRegression()}\n",
      "Starting pipeline using method: EvaluationType.BASIC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  poincare_embedding_dim1  \\\n",
      "0    23381    LR  model      F1            BE                 0.007151   \n",
      "1    23381    LR  model      F1  BUCV10RGLMME                 0.095912   \n",
      "2    23381    LR  model      F1      BUCV10TE                 0.048728   \n",
      "3    23381    LR  model      F1   BUCV2RGLMME                 0.082937   \n",
      "4    23381    LR  model      F1       BUCV2TE                 0.042925   \n",
      "\n",
      "   poincare_embedding_dim2  \n",
      "0                 0.085302  \n",
      "1                 0.152033  \n",
      "2                -0.160407  \n",
      "3                 0.130173  \n",
      "4                -0.138942  \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   poincare_embedding_dim1  poincare_embedding_dim2\n",
      "0                 0.007151                 0.085302\n",
      "1                 0.095912                 0.152033\n",
      "2                 0.048728                -0.160407\n",
      "3                 0.082937                 0.130173\n",
      "4                 0.042925                -0.138942\n",
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   dataset model tuning scoring       encoder  poincare_embedding_dim1  \\\n",
      "0    41007   SVC     no     ACC            BE                 0.007151   \n",
      "1    41007   SVC     no     ACC  BUCV10RGLMME                 0.095912   \n",
      "2    41007   SVC     no     ACC      BUCV10TE                 0.048728   \n",
      "3    41007   SVC     no     ACC   BUCV2RGLMME                 0.082937   \n",
      "4    41007   SVC     no     ACC       BUCV2TE                 0.042925   \n",
      "\n",
      "   poincare_embedding_dim2  \n",
      "0                 0.085302  \n",
      "1                 0.152033  \n",
      "2                -0.160407  \n",
      "3                 0.130173  \n",
      "4                -0.138942  \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Printing dataframe:\n",
      "   poincare_embedding_dim1  poincare_embedding_dim2\n",
      "0                 0.007151                 0.085302\n",
      "1                 0.095912                 0.152033\n",
      "2                 0.048728                -0.160407\n",
      "3                 0.082937                 0.130173\n",
      "4                 0.042925                -0.138942\n",
      "----------------------------------------\n",
      "0.09019290164218412\n",
      "Finished running the pipeline\n"
     ]
    }
   ],
   "source": [
    "pipeline.clear_steps()\n",
    "\n",
    "# create poincare transformer\n",
    "from src.pipeline.pipeline_transformers import PoincareEmbedding\n",
    "poincare_embedddings_transformer = PoincareEmbedding(graph=graph, epochs=100)\n",
    "\n",
    "# add the column transformer to the pipeline\n",
    "pipeline.add_new_step(poincare_embedddings_transformer, \"embeddings_transformer\")\n",
    "\n",
    "pipeline.add_new_step(PrintDataframe(verbose=pipeline._verbose_level), \"print_df_1\")\n",
    "\n",
    "pipeline.add_new_step(ColumnKeeper(columns=[\"poincare_embedding_dim1\", \"poincare_embedding_dim2\"]),\n",
    "                                  \"column_keeper\")\n",
    "\n",
    "pipeline.add_new_step(PrintDataframe(verbose=pipeline._verbose_level), \"print_df_2\")\n",
    "\n",
    "print(pipeline.get_pipeline().named_steps)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline using method: EvaluationType.GRID_SEARCH\n",
      "Performing grid search\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'epochs' for estimator PoincareEmbedding(graph=<networkx.classes.graph.Graph object at 0x000001F81CE72A90>). Valid parameters are: ['graph'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 211, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 70, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 236, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 205, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'epochs' for estimator PoincareEmbedding(graph=<networkx.classes.graph.Graph object at 0x000001F81CE72A90>). Valid parameters are: ['graph'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m grid_pipeline\u001b[39m.\u001b[39madd_new_step(PrintDataframe(verbose\u001b[39m=\u001b[39mgrid_pipeline\u001b[39m.\u001b[39m_verbose_level), \u001b[39m\"\u001b[39m\u001b[39mprint_df_1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m grid_pipeline\u001b[39m.\u001b[39mchange_estimator(LinearRegression())\n\u001b[1;32m---> 17\u001b[0m grid_pipeline\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32m~\\Workspace\\phase-2\\src\\pipeline\\model_pipeline.py:124\u001b[0m, in \u001b[0;36mModelPipeline.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation \u001b[39m==\u001b[39m EvaluationType\u001b[39m.\u001b[39mGRID_SEARCH:   \n\u001b[0;32m    123\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_target(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target)    \n\u001b[1;32m--> 124\u001b[0m     validation_performance_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_grid_search(X_train, y_train, param_grid\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_param_grid)\n\u001b[0;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown evaluation type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Workspace\\phase-2\\src\\pipeline\\model_pipeline.py:383\u001b[0m, in \u001b[0;36mModelPipeline._do_grid_search\u001b[1;34m(self, X_train, y_train, param_grid, cv, n_jobs)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m    377\u001b[0m     grid_search \u001b[39m=\u001b[39m GridSearchCV(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline, \n\u001b[0;32m    378\u001b[0m                             param_grid, \n\u001b[0;32m    379\u001b[0m                             scoring\u001b[39m=\u001b[39mscoring, \n\u001b[0;32m    380\u001b[0m                             cv\u001b[39m=\u001b[39mevaluate_regression\u001b[39m.\u001b[39mCustomSplit(factors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_factors, train_size\u001b[39m=\u001b[39m\u001b[39m0.75\u001b[39m), \n\u001b[0;32m    381\u001b[0m                             n_jobs\u001b[39m=\u001b[39mn_jobs, \n\u001b[0;32m    382\u001b[0m                             verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose_level)\n\u001b[1;32m--> 383\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m    384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m    386\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinished performing grid search\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose_level \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'epochs' for estimator PoincareEmbedding(graph=<networkx.classes.graph.Graph object at 0x000001F81CE72A90>). Valid parameters are: ['graph']."
     ]
    }
   ],
   "source": [
    "# using grid search to find the best parameters\n",
    "param_grid = {\n",
    "    \"embeddings_transformer__epochs\": [10, 20]\n",
    "}\n",
    "\n",
    "grid_pipeline = pipelineFactory.create_pipeline(train_df,\n",
    "                                                ModelType.REGRE_BASELINE,\n",
    "                                                verbose_level=1,\n",
    "                                                evaluation=EvaluationType.GRID_SEARCH,\n",
    "                                                param_grid=param_grid,\n",
    "                                                split_factors=[])\n",
    "grid_pipeline.add_new_step(poincare_embedddings_transformer, \"embeddings_transformer\")\n",
    "grid_pipeline.add_new_step(ColumnKeeper(columns=[\"poincare_embedding_dim1\", \"poincare_embedding_dim2\"]), \"column_keeper\")\n",
    "grid_pipeline.add_new_step(PrintDataframe(verbose=grid_pipeline._verbose_level), \"print_df_1\")\n",
    "grid_pipeline.change_estimator(LinearRegression())\n",
    "\n",
    "grid_pipeline.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
