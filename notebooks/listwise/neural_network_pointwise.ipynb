{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network pointwise\n",
    "This model is created based on the following [post](https://www.tensorflow.org/tutorials/load_data/csv#mixed_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import configuration as config\n",
    "from src.pipeline.evaluation.evaluation_utils import custom_train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset      int64\n",
      "model       object\n",
      "tuning      object\n",
      "scoring     object\n",
      "encoder     object\n",
      "rank       float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>tuning</th>\n",
       "      <th>scoring</th>\n",
       "      <th>encoder</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114</td>\n",
       "      <td>KNC</td>\n",
       "      <td>no</td>\n",
       "      <td>F1</td>\n",
       "      <td>BE</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1114</td>\n",
       "      <td>KNC</td>\n",
       "      <td>no</td>\n",
       "      <td>F1</td>\n",
       "      <td>BUCV10RGLMME</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1114</td>\n",
       "      <td>KNC</td>\n",
       "      <td>no</td>\n",
       "      <td>F1</td>\n",
       "      <td>BUCV10TE</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1114</td>\n",
       "      <td>KNC</td>\n",
       "      <td>no</td>\n",
       "      <td>F1</td>\n",
       "      <td>BUCV2RGLMME</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1114</td>\n",
       "      <td>KNC</td>\n",
       "      <td>no</td>\n",
       "      <td>F1</td>\n",
       "      <td>BUCV2TE</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model tuning scoring       encoder  rank\n",
       "0     1114   KNC     no      F1            BE  21.0\n",
       "1     1114   KNC     no      F1  BUCV10RGLMME  19.0\n",
       "2     1114   KNC     no      F1      BUCV10TE  26.0\n",
       "3     1114   KNC     no      F1   BUCV2RGLMME  12.0\n",
       "4     1114   KNC     no      F1       BUCV2TE  28.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "df = config.load_traindata_for_pointwise()\n",
    "df = df.drop(columns=['cv_score'])\n",
    "# use custom train test split\n",
    "X_train, X_test, y_train, y_test = custom_train_test_split(df, factors=[\"dataset\", \"model\", \"tuning\", \"scoring\"], target=\"rank\")\n",
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>tuning</th>\n",
       "      <th>scoring</th>\n",
       "      <th>encoder_rankings</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>ACC</td>\n",
       "      <td>[[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>F1</td>\n",
       "      <td>[[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>model</td>\n",
       "      <td>AUC</td>\n",
       "      <td>[[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>model</td>\n",
       "      <td>F1</td>\n",
       "      <td>[[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>AUC</td>\n",
       "      <td>[[DE, CBE, CE, SE, OE, BE, OHE, MHE, PBTE01, C...</td>\n",
       "      <td>[[29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model tuning scoring  \\\n",
       "0       3   DTC   full     ACC   \n",
       "1       3   DTC   full      F1   \n",
       "2       3   DTC  model     AUC   \n",
       "3       3   DTC  model      F1   \n",
       "4       3   KNC  model     AUC   \n",
       "\n",
       "                                    encoder_rankings  \\\n",
       "0  [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "1  [[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "2  [[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "3  [[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "4  [[DE, CBE, CE, SE, OE, BE, OHE, MHE, PBTE01, C...   \n",
       "\n",
       "                                             ranking  \n",
       "0  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "1  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "2  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...  \n",
       "3  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...  \n",
       "4  [[29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_encoder_rankings(df):\n",
    "    # Group the DataFrame by 'dataset', 'model', 'tuning', and 'scoring' columns\n",
    "    grouped_df = df.groupby(['dataset', 'model', 'tuning', 'scoring'])\n",
    "    \n",
    "    # Create a new DataFrame to store the results\n",
    "    new_df = pd.DataFrame(columns=['dataset', 'model', 'tuning', 'scoring', 'encoder_rankings'])\n",
    "    \n",
    "    for group_keys, group_data in grouped_df:\n",
    "        dataset, model, tuning, scoring = group_keys\n",
    "        encoder_rankings = group_data.sort_values('rank', ascending=False)['encoder'].tolist()\n",
    "        rankings = group_data.sort_values('rank', ascending=False)['rank'].tolist()\n",
    "        new_row = {'dataset': dataset, 'model': model, 'tuning': tuning, 'scoring': scoring,\n",
    "                   'encoder_rankings': [encoder_rankings], 'ranking': [rankings]}\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "df_listwise = create_encoder_rankings(df)\n",
    "df_listwise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatypes: \n",
      "dataset     int32\n",
      "model      object\n",
      "tuning     object\n",
      "scoring    object\n",
      "dtype: object\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dataset')>,\n",
       " 'model': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'model')>,\n",
       " 'tuning': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'tuning')>,\n",
       " 'scoring': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'scoring')>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.copy()\n",
    "features['dataset'] = features['dataset'].astype(int)\n",
    "labels = features.pop('rank')\n",
    "features = features[['dataset', 'model', 'tuning', 'scoring']]\n",
    "print(f\"Datatypes: \\n{features.dtypes}\\n\")\n",
    "\n",
    "inputs = {}\n",
    "\n",
    "for name, column in features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dataset')>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'normalization_2')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first step in your preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:\n",
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "print(numeric_inputs)\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(features[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the string inputs use the tf.keras.layers.StringLookup function to map from strings to integer indices in a vocabulary. Next, use tf.keras.layers.CategoryEncoding to convert the indexes into float32 data appropriate for the model.\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
       "array([[-0.8266589,  0.       ,  0.       ,  1.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         1.       ,  0.       ,  0.       ,  0.       ,  1.       ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_features_dict = {name: np.array(value) \n",
    "                         for name, value in features.items()}\n",
    "\n",
    "# Slice out the first training example and pass it to this preprocessing model, you see the numeric features and string one-hots all concatenated together:\n",
    "features_dict = {name:values[:1] for name, values in tmp_features_dict.items()}\n",
    "preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "pointwise_model = pointwise_model(preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844/844 [==============================] - 3s 2ms/step - loss: -1282.0010\n",
      "Epoch 2/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -8687.2012\n",
      "Epoch 3/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -22062.6465\n",
      "Epoch 4/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -40279.7539\n",
      "Epoch 5/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -62636.4805\n",
      "Epoch 6/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -88751.9688\n",
      "Epoch 7/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -118565.6172\n",
      "Epoch 8/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -151923.2969\n",
      "Epoch 9/10\n",
      "844/844 [==============================] - 1s 2ms/step - loss: -188592.2812\n",
      "Epoch 10/10\n",
      "844/844 [==============================] - 2s 2ms/step - loss: -228650.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24975ff78d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_model.fit(x=tmp_features_dict, y=labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"model_4\" expects 4 input(s), but it received 1 input tensors. Inputs received: [      dataset  model tuning scoring       encoder  rank\n0       43098    KNC   full     AUC            BE  25.0\n1       43098    KNC   full     AUC  BUCV10RGLMME  19.0\n2       43098    KNC   full     AUC      BUCV10TE  21.0\n3       43098    KNC   full     AUC   BUCV2RGLMME  11.0\n4       43098    KNC   full     AUC       BUCV2TE   0.0\n...       ...    ...    ...     ...           ...   ...\n9060    43897  LGBMC     no     ACC        PBTE01   0.0\n9061    43897  LGBMC     no     ACC        RGLMME   0.0\n9062    43897  LGBMC     no     ACC            SE   0.0\n9063    43897  LGBMC     no     ACC            TE   0.0\n9064    43897  LGBMC     no     ACC          WOEE   0.0\n\n[9065 rows x 6 columns]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Test the model with the df_test data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m body \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      7\u001b[0m     layers\u001b[39m.\u001b[39mDense(\u001b[39m64\u001b[39m),\n\u001b[0;32m      8\u001b[0m     layers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m   ])\n\u001b[1;32m---> 11\u001b[0m preprocessed_inputs \u001b[39m=\u001b[39m preprocessing(df_test)\n\u001b[0;32m     12\u001b[0m result \u001b[39m=\u001b[39m body(preprocessed_inputs)\n\u001b[0;32m     13\u001b[0m y_pred \u001b[39m=\u001b[39m pointwise_model\u001b[39m.\u001b[39mpredict(result)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:219\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs to a layer should be tensors. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m) as input for layer \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m \u001b[39mfor\u001b[39;00m input_index, (x, spec) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"model_4\" expects 4 input(s), but it received 1 input tensors. Inputs received: [      dataset  model tuning scoring       encoder  rank\n0       43098    KNC   full     AUC            BE  25.0\n1       43098    KNC   full     AUC  BUCV10RGLMME  19.0\n2       43098    KNC   full     AUC      BUCV10TE  21.0\n3       43098    KNC   full     AUC   BUCV2RGLMME  11.0\n4       43098    KNC   full     AUC       BUCV2TE   0.0\n...       ...    ...    ...     ...           ...   ...\n9060    43897  LGBMC     no     ACC        PBTE01   0.0\n9061    43897  LGBMC     no     ACC        RGLMME   0.0\n9062    43897  LGBMC     no     ACC            SE   0.0\n9063    43897  LGBMC     no     ACC            TE   0.0\n9064    43897  LGBMC     no     ACC          WOEE   0.0\n\n[9065 rows x 6 columns]]"
     ]
    }
   ],
   "source": [
    "from src.pipeline.evaluation import evaluation_utils as er\n",
    "\n",
    "factors = [\"dataset\", \"model\", \"tuning\", \"scoring\"]\n",
    "new_index = \"encoder\"\n",
    "# Test the model with the df_test data\n",
    "body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "preprocessed_inputs = preprocessing(df_test)\n",
    "result = body(preprocessed_inputs)\n",
    "y_pred = pointwise_model.predict(result)\n",
    "\n",
    "df_pred = pd.concat([X_test, y_test, y_pred], axis=1)\n",
    "# ---- convert to rankings and evaluate\n",
    "rankings_test = er.get_rankings(\n",
    "    df_pred,\n",
    "    factors=factors,\n",
    "    new_index=new_index,\n",
    "    target=\"cv_score\"\n",
    ")\n",
    "rankings_pred = er.get_rankings(\n",
    "    df_pred,\n",
    "    factors=factors,\n",
    "    new_index=new_index,\n",
    "    target=\"cv_score_pred\"\n",
    ")\n",
    "score = er.average_spearman(\n",
    "    rankings_test,\n",
    "    rankings_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pointwise_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pointwise_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Since the preprocessing is part of the model, you can save the model and reload it somewhere else and get identical results:\n",
    "pointwise_model.save('pointwise_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"concatenate_2\" (type Concatenate).\n\nA merge layer should be called on a list of inputs. Received: inputs=Tensor(\"Placeholder:0\", shape=(None, 1), dtype=float32) (not a list of tensors)\n\nCall arguments received by layer \"concatenate_2\" (type Concatenate):\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reloaded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mpointwise_model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    231\u001b[0m         filepath,\n\u001b[0;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    233\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    240\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\layers\\merging\\base_merge.py:123\u001b[0m, in \u001b[0;36m_Merge.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m    122\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m--> 123\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    124\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA merge layer should be called on a list of inputs. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: inputs=\u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m (not a list of tensors)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m         )\n\u001b[0;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reshape_required:\n\u001b[0;32m    128\u001b[0m         reshaped_inputs \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"concatenate_2\" (type Concatenate).\n\nA merge layer should be called on a list of inputs. Received: inputs=Tensor(\"Placeholder:0\", shape=(None, 1), dtype=float32) (not a list of tensors)\n\nCall arguments received by layer \"concatenate_2\" (type Concatenate):\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "reloaded = tf.keras.models.load_model('pointwise_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
