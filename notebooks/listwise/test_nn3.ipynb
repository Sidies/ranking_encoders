{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import configuration as config\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset      int64\n",
      "model       object\n",
      "tuning      object\n",
      "scoring     object\n",
      "encoder     object\n",
      "rank       float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>tuning</th>\n",
       "      <th>scoring</th>\n",
       "      <th>encoder</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>BUCV2RGLMME</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>BUCV2TE</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CBE</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CE</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CV10RGLMME</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model tuning scoring      encoder  rank\n",
       "0     1169   KNC  model     ACC  BUCV2RGLMME  16.0\n",
       "1     1169   KNC  model     ACC      BUCV2TE  14.0\n",
       "2     1169   KNC  model     ACC          CBE  22.0\n",
       "3     1169   KNC  model     ACC           CE  23.0\n",
       "4     1169   KNC  model     ACC   CV10RGLMME   7.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "df = config.load_traindata_for_pointwise()\n",
    "df = df.drop(columns=['cv_score'])\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>tuning</th>\n",
       "      <th>scoring</th>\n",
       "      <th>encoder_rankings</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>ACC</td>\n",
       "      <td>[[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>AUC</td>\n",
       "      <td>[[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>F1</td>\n",
       "      <td>[[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>model</td>\n",
       "      <td>AUC</td>\n",
       "      <td>[[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>model</td>\n",
       "      <td>F1</td>\n",
       "      <td>[[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model tuning scoring  \\\n",
       "0       3   DTC   full     ACC   \n",
       "1       3   DTC   full     AUC   \n",
       "2       3   DTC   full      F1   \n",
       "3       3   DTC  model     AUC   \n",
       "4       3   DTC  model      F1   \n",
       "\n",
       "                                    encoder_rankings  \\\n",
       "0  [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "1  [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "2  [[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "3  [[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "4  [[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "\n",
       "                                             ranking  \n",
       "0  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "1  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "2  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "3  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...  \n",
       "4  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_encoder_rankings(df):\n",
    "    # Group the DataFrame by 'dataset', 'model', 'tuning', and 'scoring' columns\n",
    "    grouped_df = df.groupby(['dataset', 'model', 'tuning', 'scoring'])\n",
    "    \n",
    "    # Create a new DataFrame to store the results\n",
    "    new_df = pd.DataFrame(columns=['dataset', 'model', 'tuning', 'scoring', 'encoder_rankings'])\n",
    "    \n",
    "    for group_keys, group_data in grouped_df:\n",
    "        dataset, model, tuning, scoring = group_keys\n",
    "        encoder_rankings = group_data.sort_values('rank', ascending=False)['encoder'].tolist()\n",
    "        rankings = group_data.sort_values('rank', ascending=False)['rank'].tolist()\n",
    "        new_row = {'dataset': dataset, 'model': model, 'tuning': tuning, 'scoring': scoring,\n",
    "                   'encoder_rankings': [encoder_rankings], 'ranking': [rankings]}\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "df_listwise = create_encoder_rankings(df)\n",
    "df_listwise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatypes: \n",
      "dataset     int32\n",
      "model      object\n",
      "tuning     object\n",
      "scoring    object\n",
      "dtype: object\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dataset')>,\n",
       " 'model': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'model')>,\n",
       " 'tuning': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'tuning')>,\n",
       " 'scoring': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'scoring')>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.copy()\n",
    "features['dataset'] = features['dataset'].astype(int)\n",
    "labels = features.pop('rank')\n",
    "features = features[['dataset', 'model', 'tuning', 'scoring']]\n",
    "print(f\"Datatypes: \\n{features.dtypes}\\n\")\n",
    "\n",
    "inputs = {}\n",
    "\n",
    "for name, column in features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dataset')>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'normalization_1')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first step in your preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:\n",
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "print(numeric_inputs)\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(features[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the string inputs use the tf.keras.layers.StringLookup function to map from strings to integer indices in a vocabulary. Next, use tf.keras.layers.CategoryEncoding to convert the indexes into float32 data appropriate for the model.\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
       "array([[-0.8206538,  0.       ,  0.       ,  1.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  1.       ,\n",
       "         0.       ,  0.       ,  1.       ,  0.       ,  0.       ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_features_dict = {name: np.array(value) \n",
    "                         for name, value in features.items()}\n",
    "\n",
    "# Slice out the first training example and pass it to this preprocessing model, you see the numeric features and string one-hots all concatenated together:\n",
    "features_dict = {name:values[:1] for name, values in tmp_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'sequential_4')>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "body = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "preprocessed_inputs = titanic_preprocessing(inputs)\n",
    "result = body(preprocessed_inputs)\n",
    "result\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 61, in compute_loss\n        raise NotImplementedError(\n\n    NotImplementedError: Implementers must implement the `compute_loss` method.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m titanic_model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtmp_features_dict, y\u001b[39m=\u001b[39;49mlabels, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileq1_aevom.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(inputs, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[39m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py:61\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(\u001b[39mself\u001b[39m, inputs, training: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     50\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Defines the loss function.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39m    Loss tensor.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     62\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mImplementers must implement the `compute_loss` method.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 61, in compute_loss\n        raise NotImplementedError(\n\n    NotImplementedError: Implementers must implement the `compute_loss` method.\n"
     ]
    }
   ],
   "source": [
    "titanic_model.fit(x=tmp_features_dict, y=labels, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
