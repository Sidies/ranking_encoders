{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import configuration as config\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset      int64\n",
      "model       object\n",
      "tuning      object\n",
      "scoring     object\n",
      "encoder     object\n",
      "rank       float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>tuning</th>\n",
       "      <th>scoring</th>\n",
       "      <th>encoder</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>BUCV2RGLMME</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>BUCV2TE</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CBE</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CE</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1169</td>\n",
       "      <td>KNC</td>\n",
       "      <td>model</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CV10RGLMME</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model tuning scoring      encoder  rank\n",
       "0     1169   KNC  model     ACC  BUCV2RGLMME  16.0\n",
       "1     1169   KNC  model     ACC      BUCV2TE  14.0\n",
       "2     1169   KNC  model     ACC          CBE  22.0\n",
       "3     1169   KNC  model     ACC           CE  23.0\n",
       "4     1169   KNC  model     ACC   CV10RGLMME   7.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "df = config.load_traindata_for_pointwise()\n",
    "df = df.drop(columns=['cv_score'])\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>tuning</th>\n",
       "      <th>scoring</th>\n",
       "      <th>encoder_rankings</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>ACC</td>\n",
       "      <td>[[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>AUC</td>\n",
       "      <td>[[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>full</td>\n",
       "      <td>F1</td>\n",
       "      <td>[[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>model</td>\n",
       "      <td>AUC</td>\n",
       "      <td>[[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>DTC</td>\n",
       "      <td>model</td>\n",
       "      <td>F1</td>\n",
       "      <td>[[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model tuning scoring  \\\n",
       "0       3   DTC   full     ACC   \n",
       "1       3   DTC   full     AUC   \n",
       "2       3   DTC   full      F1   \n",
       "3       3   DTC  model     AUC   \n",
       "4       3   DTC  model      F1   \n",
       "\n",
       "                                    encoder_rankings  \\\n",
       "0  [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "1  [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "2  [[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "3  [[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "4  [[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "\n",
       "                                             ranking  \n",
       "0  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "1  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "2  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "3  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...  \n",
       "4  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_encoder_rankings(df):\n",
    "    # Group the DataFrame by 'dataset', 'model', 'tuning', and 'scoring' columns\n",
    "    grouped_df = df.groupby(['dataset', 'model', 'tuning', 'scoring'])\n",
    "    \n",
    "    # Create a new DataFrame to store the results\n",
    "    new_df = pd.DataFrame(columns=['dataset', 'model', 'tuning', 'scoring', 'encoder_rankings'])\n",
    "    \n",
    "    for group_keys, group_data in grouped_df:\n",
    "        dataset, model, tuning, scoring = group_keys\n",
    "        encoder_rankings = group_data.sort_values('rank', ascending=False)['encoder'].tolist()\n",
    "        rankings = group_data.sort_values('rank', ascending=False)['rank'].tolist()\n",
    "        new_row = {'dataset': dataset, 'model': model, 'tuning': tuning, 'scoring': scoring,\n",
    "                   'encoder_rankings': [encoder_rankings], 'ranking': [rankings]}\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "df_listwise = create_encoder_rankings(df)\n",
    "df_listwise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder_rankings</th>\n",
       "      <th>ranking</th>\n",
       "      <th>dataset_model_tuning_scoring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>3 DTC full ACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>3 DTC full AUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...</td>\n",
       "      <td>[[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>3 DTC full F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "      <td>3 DTC model AUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...</td>\n",
       "      <td>[[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...</td>\n",
       "      <td>3 DTC model F1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    encoder_rankings  \\\n",
       "0  [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "1  [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "2  [[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...   \n",
       "3  [[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "4  [[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...   \n",
       "\n",
       "                                             ranking  \\\n",
       "0  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "1  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "2  [[4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "3  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...   \n",
       "4  [[25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18...   \n",
       "\n",
       "  dataset_model_tuning_scoring  \n",
       "0               3 DTC full ACC  \n",
       "1               3 DTC full AUC  \n",
       "2                3 DTC full F1  \n",
       "3              3 DTC model AUC  \n",
       "4               3 DTC model F1  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat dataset model tuning scoring into one column\n",
    "df_listwise['dataset_model_tuning_scoring'] = df_listwise['dataset'].astype(str) + ' ' + df_listwise['model'] + ' ' + df_listwise['tuning'] + ' ' + df_listwise['scoring']\n",
    "# drop everthing but ranking and dataset_model_tuning_scoring\n",
    "df_listwise = df_listwise.drop(columns=['dataset', 'model', 'tuning', 'scoring'])\n",
    "df_listwise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'1037 DTC full AUC' b'1037 DTC full F1' b'1037 DTC model ACC' ...\n",
      " b'981 SVC no ACC' b'981 SVC no AUC' b'981 SVC no F1']\n",
      "['BE' 'BUCV10RGLMME' 'BUCV10TE' 'BUCV2RGLMME' 'BUCV2TE' 'BUCV5RGLMME'\n",
      " 'BUCV5TE' 'CBE' 'CE' 'CV10RGLMME' 'CV10TE' 'CV2RGLMME' 'CV2TE'\n",
      " 'CV5RGLMME' 'CV5TE' 'DE' 'DTEM10' 'DTEM2' 'DTEM5' 'ME01E' 'ME10E' 'ME1E'\n",
      " 'MHE' 'OE' 'OHE' 'PBTE0001' 'PBTE001' 'PBTE01' 'RGLMME' 'SE' 'TE' 'WOEE']\n"
     ]
    }
   ],
   "source": [
    "# convert to a array containing all unique combinations of model, tuning, scoring as byte strings\n",
    "# unique_factor_combinations = np.unique(df_listwise[['model', 'tuning', 'scoring']])\n",
    "# unique_factor_combinations = unique_factor_combinations.astype('S')\n",
    "# print(unique_factor_combinations)\n",
    "\n",
    "# unique_model_combinations = np.unique(df_listwise['model'])\n",
    "# unique_model_combinations = unique_factor_combinations.astype('S')\n",
    "\n",
    "# unique_tuning_combinations = np.unique(df_listwise['tuning'])\n",
    "# unique_tuning_combinations = unique_factor_combinations.astype('S')\n",
    "\n",
    "unique_factor_combinations = np.unique(df_listwise[['dataset_model_tuning_scoring']])\n",
    "unique_factor_combinations = unique_factor_combinations.astype('S')\n",
    "print(unique_factor_combinations)\n",
    "\n",
    "unique_encoder_rankings = np.unique(df[['encoder']])\n",
    "#unique_encoder_rankings = unique_encoder_rankings.astype('S')\n",
    "print(unique_encoder_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dict(inputs, fun=tf.stack):\n",
    "    values = []\n",
    "    for key in sorted(inputs.keys()):\n",
    "      values.append(tf.cast(inputs[key], tf.float32))\n",
    "\n",
    "    return fun(values, axis=-1)\n",
    "\n",
    "class RankingModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, loss):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "    print(\"STARTING INIT\")\n",
    "    # Compute embeddings for factor combinations.\n",
    "    self.factors_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_factor_combinations),\n",
    "      tf.keras.layers.Embedding(len(unique_factor_combinations) + 2, embedding_dimension)\n",
    "    ])\n",
    "    \n",
    "    # # Compute embeddings for factor combinations.\n",
    "    # self.model_embeddings = tf.keras.Sequential([\n",
    "    #   tf.keras.layers.StringLookup(\n",
    "    #     vocabulary=unique_model_combinations),\n",
    "    #   tf.keras.layers.Embedding(len(unique_model_combinations) + 2, embedding_dimension)\n",
    "    # ])\n",
    "    \n",
    "    # # Compute embeddings for factor combinations.\n",
    "    # self.tuning_embeddings = tf.keras.Sequential([\n",
    "    #   tf.keras.layers.StringLookup(\n",
    "    #     vocabulary=unique_tuning_combinations),\n",
    "    #   tf.keras.layers.Embedding(len(unique_tuning_combinations) + 2, embedding_dimension)\n",
    "    # ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.score_model = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "      loss=loss,\n",
    "      metrics=[\n",
    "        tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "        tf.keras.metrics.RootMeanSquaredError()\n",
    "      ]\n",
    "    )\n",
    "    print(\"FINISHED INIT\")\n",
    "\n",
    "  def call(self, features):\n",
    "    # We first convert the id features into embeddings.\n",
    "    print(\"We are in call\")\n",
    "    \n",
    "    factors = [\"model\", \"tuning\"]\n",
    "    print(\"Factors can be printed {}\", factors)\n",
    "    print(f\"The type of features is {type(features)}\")\n",
    "    # #factors = (\"model\", \"tuning\", \"scoring\")\n",
    "    # #factors = tuple(features[f].ref() for f in factors)  # convert factors list to tuple\n",
    "    \n",
    "    factors_embeddings = self.factors_embeddings(features[\"dataset_model_tuning_scoring\"])\n",
    "    \n",
    "    # We first convert the id features into embeddings.\n",
    "    # User embeddings are a [batch_size, embedding_dim] tensor.\n",
    "    #model_embeddings = self.model_embeddings(features[\"model\"])\n",
    "\n",
    "    # Movie embeddings are a [batch_size, num_movies_in_list, embedding_dim]\n",
    "    # tensor.\n",
    "    #tuning_embeddings = self.tuning_embeddings(features[\"tuning\"])\n",
    "\n",
    "    # We want to concatenate user embeddings with movie emebeddings to pass\n",
    "    # them into the ranking model. To do so, we need to reshape the user\n",
    "    # embeddings to match the shape of movie embeddings.\n",
    "    print(features)\n",
    "    print(features[\"model\"])\n",
    "    #list_length = features[\"model\"].shape[1]\n",
    "    #user_embedding_repeated = tf.repeat(\n",
    "    #    tf.expand_dims(tuning_embeddings, 1), [list_length], axis=1)\n",
    "\n",
    "    # Once reshaped, we concatenate and pass into the dense layers to generate\n",
    "    # predictions.\n",
    "    # concatenated_embeddings = tf.concat(\n",
    "    #     [tuning_embeddings, model_embeddings], 2)\n",
    "\n",
    "    # user_emb = tf.expand_dims(model_embeddings, axis=1)\n",
    "    # movie_emb = tf.expand_dims(tuning_embeddings, axis=1)\n",
    "    # inputs = [user_emb, movie_emb]\n",
    "    # concatenated_embeddings = tf.concat(inputs, axis=1)\n",
    "    # return self.score_model(concatenated_embeddings)\n",
    "    return self.score_model(factors_embeddings)\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    print(\"Computing Loss\")\n",
    "    labels = features.pop(\"dataset\")  \n",
    "    scores = self(features)\n",
    "\n",
    "    return self.task(\n",
    "        labels=labels,\n",
    "        predictions=tf.squeeze(scores, axis=-1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "# cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "# cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['scoring'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_df \u001b[39m=\u001b[39m df_listwise\n\u001b[0;32m      2\u001b[0m train_df\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mencoder_rankings\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m train_df\u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mscoring\u001b[39;49m\u001b[39m\"\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      4\u001b[0m train_df\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mranking\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m train_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6694\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6695\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6696\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6697\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6698\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['scoring'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_df = df_listwise\n",
    "train_df.drop(\"encoder_rankings\", axis=1, inplace=True)\n",
    "train_df.drop(\"scoring\", axis=1, inplace=True)\n",
    "train_df.drop(\"ranking\", axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING INIT\n",
      "FINISHED INIT\n"
     ]
    }
   ],
   "source": [
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss())\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset    int64\n",
      "model      int32\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:104\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     spec \u001b[39m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[39m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[39m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:507\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    504\u001b[0m     logging\u001b[39m.\u001b[39mvlog(\n\u001b[0;32m    505\u001b[0m         \u001b[39m3\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to convert \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m to tensor: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mtype\u001b[39m(element)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, e))\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not build a `TypeSpec` for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    508\u001b[0m     element,\n\u001b[0;32m    509\u001b[0m     \u001b[39mtype\u001b[39m(element)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 0       [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...\n1       [[DE, CBE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...\n2       [[CBE, DE, PBTE01, BE, OE, ME01E, ME10E, ME1E,...\n3       [[DE, CBE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...\n4       [[CBE, DE, PBTE01, CV2TE, CV2RGLMME, CV5RGLMME...\n                              ...                        \n1156    [[DE, PBTE01, PBTE001, ME10E, ME1E, RGLMME, CV...\n1157    [[CE, MHE, DE, CV5RGLMME, CV2TE, CV10TE, BUCV2...\n1158    [[DE, OE, ME10E, CV10RGLMME, CV2RGLMME, BUCV10...\n1159    [[DE, OE, ME10E, CV10RGLMME, CV2RGLMME, BUCV10...\n1160    [[DE, OE, ME10E, CV10RGLMME, CV2RGLMME, BUCV10...\nName: encoder_rankings, Length: 1161, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 26\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(test_df\u001b[39m.\u001b[39mdtypes)\n\u001b[0;32m     17\u001b[0m \u001b[39m# training_dataset = (\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m#     tf.data.Dataset.from_tensor_slices(\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m#         (\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m training_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices(\u001b[39mdict\u001b[39;49m(df_listwise))\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:831\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[39m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_tensor_slices_op\n\u001b[1;32m--> 831\u001b[0m \u001b[39mreturn\u001b[39;00m from_tensor_slices_op\u001b[39m.\u001b[39;49m_from_tensor_slices(tensors, name)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 25\u001b[0m   \u001b[39mreturn\u001b[39;00m _TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, element, is_files\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m   element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mnormalize_element(element)\n\u001b[0;32m     34\u001b[0m   batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m     35\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:109\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    104\u001b[0m     spec \u001b[39m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[39m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[39m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m   normalized_components\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 109\u001b[0m       ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomponent_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m i))\n\u001b[0;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m   \u001b[39m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m   \u001b[39m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m   \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDatasetSpec\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1443\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[1;32m-> 1443\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[0;32m   1444\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[0;32m   1445\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    323\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    279\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    284\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    286\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "numerical_feature_names = ['dataset']\n",
    "categorical_feature_names = ['model']\n",
    "list_feature_names = ['encoder_rankings']\n",
    "df = df.drop(columns=['rank', 'scoring', 'encoder', 'tuning'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "test_df = df.copy()\n",
    "# Fit and transform the string column to obtain encoded values\n",
    "test_df['model'] = label_encoder.fit_transform(df['model'])\n",
    "#test_df['tuning'] = label_encoder.fit_transform(df['tuning'])\n",
    "\n",
    "print(test_df.dtypes)\n",
    "\n",
    "# training_dataset = (\n",
    "#     tf.data.Dataset.from_tensor_slices(\n",
    "#         (\n",
    "#             tf.cast(test_df[categorical_feature_names].values, tf.float32),\n",
    "#             tf.cast(test_df['dataset'].values, tf.int32)\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(dict(df_listwise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': <tf.Tensor: shape=(), dtype=int64, numpy=1169>, 'model': <tf.Tensor: shape=(), dtype=int32, numpy=1>}\n"
     ]
    }
   ],
   "source": [
    "for row in training_dataset.take(1):\n",
    "  print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<_TensorSliceDataset element_spec={'model': TensorSpec(shape=(), dtype=tf.string, name=None), 'tuning': TensorSpec(shape=(), dtype=tf.string, name=None), 'scoring': TensorSpec(shape=(), dtype=tf.string, name=None)}>\n",
    "\n",
    "<CacheDataset element_spec={'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'movie_title': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)}>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Computing Loss\n",
      "We are in call\n",
      "Factors can be printed {} ['model', 'tuning']\n",
      "The type of features is <class 'dict'>\n",
      "{'model': <tf.Tensor 'IteratorGetNext:1' shape=() dtype=int32>}\n",
      "Tensor(\"IteratorGetNext:1\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_21944\\118192996.py\", line 98, in compute_loss\n        scores = self(features)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Marco\\AppData\\Local\\Temp\\__autograph_generated_file6w8k9rel.py\", line 22, in tf__call\n        raise\n\n    ValueError: Exception encountered when calling layer 'ranking_model_12' (type RankingModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_21944\\118192996.py\", line 93, in call  *\n            return self.score_model(model_embeddings)\n        File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'sequential_51' (type Sequential).\n        \n        Input 0 of layer \"dense_36\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n        \n        Call arguments received by layer 'sequential_51' (type Sequential):\n          • inputs=tf.Tensor(shape=(32,), dtype=float32)\n          • training=None\n          • mask=None\n    \n    \n    Call arguments received by layer 'ranking_model_12' (type RankingModel):\n      • features={'model': 'tf.Tensor(shape=(), dtype=int32)'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m listwise_model\u001b[39m.\u001b[39;49mfit(training_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileyo8qd_jm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(inputs, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[39m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "Cell \u001b[1;32mIn[147], line 98\u001b[0m, in \u001b[0;36mRankingModel.compute_loss\u001b[1;34m(self, features, training)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mComputing Loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m labels \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m)  \n\u001b[1;32m---> 98\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(features)\n\u001b[0;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask(\n\u001b[0;32m    101\u001b[0m     labels\u001b[39m=\u001b[39mlabels,\n\u001b[0;32m    102\u001b[0m     predictions\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39msqueeze(scores, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m    103\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file6w8k9rel.py:19\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mscore_model, (ag__\u001b[39m.\u001b[39mld(model_embeddings),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     20\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_21944\\118192996.py\", line 98, in compute_loss\n        scores = self(features)\n    File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Marco\\AppData\\Local\\Temp\\__autograph_generated_file6w8k9rel.py\", line 22, in tf__call\n        raise\n\n    ValueError: Exception encountered when calling layer 'ranking_model_12' (type RankingModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_21944\\118192996.py\", line 93, in call  *\n            return self.score_model(model_embeddings)\n        File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'sequential_51' (type Sequential).\n        \n        Input 0 of layer \"dense_36\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n        \n        Call arguments received by layer 'sequential_51' (type Sequential):\n          • inputs=tf.Tensor(shape=(32,), dtype=float32)\n          • training=None\n          • mask=None\n    \n    \n    Call arguments received by layer 'ranking_model_12' (type RankingModel):\n      • features={'model': 'tf.Tensor(shape=(), dtype=int32)'}\n"
     ]
    }
   ],
   "source": [
    "listwise_model.fit(training_dataset, epochs=2, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
