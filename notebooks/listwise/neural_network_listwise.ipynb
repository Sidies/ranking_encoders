{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import configuration as config\n",
    "from src.pipeline.evaluation.evaluation_utils import custom_train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = config.load_traindata_for_pointwise()\n",
    "df = df.drop(columns=['cv_score'])\n",
    "X_train, X_test, y_train, y_test = custom_train_test_split(df, factors=[\"dataset\", \"model\", \"tuning\", \"scoring\"], target=\"rank\")\n",
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder      object\n",
      "rank        float64\n",
      "features     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "# train data\n",
    "df['dataset'] = df['dataset'].astype(str)\n",
    "df['features'] = df['dataset'].astype(str) + ' ' + df['model'] + ' ' + df['tuning'] + ' ' + df['scoring']\n",
    "df = df.drop(columns=['dataset', 'model', 'tuning', 'scoring'])\n",
    "print(df.dtypes)\n",
    "df.head()\n",
    "\n",
    "# test data\n",
    "df_test['dataset'] = df_test['dataset'].astype(str)\n",
    "df_test['features'] = df_test['dataset'].astype(str) + ' ' + df_test['model'] + ' ' + df_test['tuning'] + ' ' + df_test['scoring']\n",
    "df_test = df_test.drop(columns=['dataset', 'model', 'tuning', 'scoring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset'>\n"
     ]
    }
   ],
   "source": [
    "df_tf = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "df_tf_test = tf.data.Dataset.from_tensor_slices(dict(df_test))\n",
    "print(type(df_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import collections\n",
    "\n",
    "from typing import Dict, List, Optional, Text, Tuple\n",
    "\n",
    "def _create_feature_dict() -> Dict[Text, List[tf.Tensor]]:\n",
    "  \"\"\"Helper function for creating an empty feature dict for defaultdict.\"\"\"\n",
    "  return {\"encoder\": [], \"rank\": []}\n",
    "\n",
    "\n",
    "def _sample_list(\n",
    "    feature_lists: Dict[Text, List[tf.Tensor]],\n",
    "    num_examples_per_list: int,\n",
    "    random_state: Optional[np.random.RandomState] = None,\n",
    ") -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "  \"\"\"Function for sampling a list example from given feature lists.\"\"\"\n",
    "  if random_state is None:\n",
    "    random_state = np.random.RandomState()\n",
    "\n",
    "  sampled_indices = random_state.choice(\n",
    "      range(len(feature_lists[\"encoder\"])),\n",
    "      size=num_examples_per_list,\n",
    "      replace=False,\n",
    "  )\n",
    "  sampled_movie_titles = [\n",
    "      feature_lists[\"encoder\"][idx] for idx in sampled_indices\n",
    "  ]\n",
    "  sampled_ratings = [\n",
    "      feature_lists[\"rank\"][idx]\n",
    "      for idx in sampled_indices\n",
    "  ]\n",
    "\n",
    "  return (\n",
    "      tf.stack(sampled_movie_titles, 0),\n",
    "      tf.stack(sampled_ratings, 0),\n",
    "  )\n",
    "\n",
    "\n",
    "def sample_listwise(\n",
    "    rating_dataset: tf.data.Dataset,\n",
    "    num_list_per_user: int = 10,\n",
    "    num_examples_per_list: int = 10,\n",
    "    seed: Optional[int] = None,\n",
    ") -> tf.data.Dataset:\n",
    "  \"\"\"Function for converting the MovieLens 100K dataset to a listwise dataset.\n",
    "\n",
    "  Args:\n",
    "      rating_dataset:\n",
    "        The MovieLens ratings dataset loaded from TFDS with features\n",
    "        \"movie_title\", \"user_id\", and \"user_rating\".\n",
    "      num_list_per_user:\n",
    "        An integer representing the number of lists that should be sampled for\n",
    "        each user in the training dataset.\n",
    "      num_examples_per_list:\n",
    "        An integer representing the number of movies to be sampled for each list\n",
    "        from the list of movies rated by the user.\n",
    "      seed:\n",
    "        An integer for creating `np.random.RandomState`.\n",
    "\n",
    "  Returns:\n",
    "      A tf.data.Dataset containing list examples.\n",
    "\n",
    "      Each example contains three keys: \"user_id\", \"movie_title\", and\n",
    "      \"user_rating\". \"user_id\" maps to a string tensor that represents the user\n",
    "      id for the example. \"movie_title\" maps to a tensor of shape\n",
    "      [sum(num_example_per_list)] with dtype tf.string. It represents the list\n",
    "      of candidate movie ids. \"user_rating\" maps to a tensor of shape\n",
    "      [sum(num_example_per_list)] with dtype tf.float32. It represents the\n",
    "      rating of each movie in the candidate list.\n",
    "  \"\"\"\n",
    "  random_state = np.random.RandomState(seed)\n",
    "\n",
    "  example_lists_by_user = collections.defaultdict(_create_feature_dict)\n",
    "\n",
    "  movie_title_vocab = set()\n",
    "  for example in rating_dataset:\n",
    "    user_id = example[\"features\"].numpy()\n",
    "    example_lists_by_user[user_id][\"encoder\"].append(\n",
    "        example[\"encoder\"])\n",
    "    example_lists_by_user[user_id][\"rank\"].append(\n",
    "        example[\"rank\"])\n",
    "    movie_title_vocab.add(example[\"encoder\"].numpy())\n",
    "\n",
    "  tensor_slices = {\"features\": [], \"encoder\": [], \"rank\": []}\n",
    "\n",
    "  for user_id, feature_lists in example_lists_by_user.items():\n",
    "    for _ in range(num_list_per_user):\n",
    "\n",
    "      # Drop the user if they don't have enough ratings.\n",
    "      if len(feature_lists[\"encoder\"]) < num_examples_per_list:\n",
    "        continue\n",
    "\n",
    "      sampled_movie_titles, sampled_ratings = _sample_list(\n",
    "          feature_lists,\n",
    "          num_examples_per_list,\n",
    "          random_state=random_state,\n",
    "      )\n",
    "      tensor_slices[\"features\"].append(user_id)\n",
    "      tensor_slices[\"encoder\"].append(sampled_movie_titles)\n",
    "      tensor_slices[\"rank\"].append(sampled_ratings)\n",
    "\n",
    "  return tf.data.Dataset.from_tensor_slices(tensor_slices)\n",
    "\n",
    "df_listwise = sample_listwise(df_tf)\n",
    "df_listwise_test = sample_listwise(df_tf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec={'features': TensorSpec(shape=(), dtype=tf.string, name=None), 'encoder': TensorSpec(shape=(10,), dtype=tf.string, name=None), 'rank': TensorSpec(shape=(10,), dtype=tf.float64, name=None)}>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoder': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'MHE', b'OHE', b'BUCV10RGLMME', b'PBTE001', b'BUCV5TE', b'CBE',\n",
      "       b'CV2TE', b'DTEM5', b'DTEM10', b'BE'], dtype=object)>,\n",
      " 'features': <tf.Tensor: shape=(), dtype=string, numpy=b'1114 KNC no F1'>,\n",
      " 'rank': <tf.Tensor: shape=(10,), dtype=float64, numpy=array([25., 15., 19.,  3., 29.,  0.,  8., 23., 22., 21.])>}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "for example in df_listwise.take(1):\n",
    "  pprint.pprint(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = df_listwise.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = df_listwise_test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset element_spec={'features': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'encoder': TensorSpec(shape=(None, 10), dtype=tf.string, name=None), 'rank': TensorSpec(shape=(None, 10), dtype=tf.float64, name=None)}>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'1037 DTC full AUC' b'1037 DTC full F1' b'1037 DTC model ACC'\n",
      " b'1037 DTC model F1' b'1037 DTC no F1' b'1037 KNC model AUC'\n",
      " b'1037 KNC model F1' b'1037 KNC no F1' b'1037 LGBMC no F1'\n",
      " b'1037 LR full ACC' b'1037 LR full F1' b'1037 LR model F1'\n",
      " b'1037 LR no ACC' b'1037 LR no AUC' b'1037 SVC full ACC'\n",
      " b'1037 SVC full AUC' b'1037 SVC full F1' b'1037 SVC no ACC'\n",
      " b'1037 SVC no AUC' b'1037 SVC no F1' b'1111 DTC model ACC'\n",
      " b'1111 DTC model AUC' b'1111 DTC no AUC' b'1111 DTC no F1'\n",
      " b'1111 KNC model ACC' b'1111 KNC model F1' b'1111 KNC no ACC'\n",
      " b'1111 LGBMC no ACC' b'1111 LGBMC no AUC' b'1111 LGBMC no F1'\n",
      " b'1111 LR model ACC' b'1111 LR model F1' b'1111 LR no AUC'\n",
      " b'1111 SVC no F1' b'1112 DTC model ACC' b'1112 DTC model F1'\n",
      " b'1112 DTC no F1' b'1112 KNC model ACC' b'1112 KNC model AUC'\n",
      " b'1112 KNC model F1' b'1112 KNC no F1' b'1112 LGBMC no F1'\n",
      " b'1112 LR model AUC' b'1112 LR no ACC' b'1112 LR no AUC' b'1112 LR no F1'\n",
      " b'1112 SVC no ACC' b'1112 SVC no F1' b'1114 DTC model F1'\n",
      " b'1114 DTC no ACC' b'1114 DTC no AUC' b'1114 KNC model ACC'\n",
      " b'1114 KNC model AUC' b'1114 KNC model F1' b'1114 KNC no ACC'\n",
      " b'1114 KNC no AUC' b'1114 KNC no F1' b'1114 LGBMC no ACC'\n",
      " b'1114 LGBMC no AUC' b'1114 LGBMC no F1' b'1114 LR no AUC'\n",
      " b'1114 SVC no AUC' b'1169 DTC model ACC' b'1169 DTC model AUC'\n",
      " b'1169 DTC model F1' b'1169 KNC model AUC' b'1169 KNC no ACC'\n",
      " b'1169 KNC no F1' b'1169 LGBMC no ACC' b'1169 LGBMC no F1'\n",
      " b'1169 LR model ACC' b'1169 LR no ACC' b'1169 LR no AUC' b'1169 LR no F1'\n",
      " b'1235 DTC model ACC' b'1235 DTC model AUC' b'1235 DTC no AUC'\n",
      " b'1235 KNC model AUC' b'1235 KNC model F1' b'1235 KNC no F1'\n",
      " b'1235 LGBMC no F1' b'1235 LR model AUC' b'1235 LR model F1'\n",
      " b'1235 LR no ACC' b'1235 LR no AUC' b'1235 LR no F1'\n",
      " b'1461 DTC model AUC' b'1461 DTC model F1' b'1461 DTC no ACC'\n",
      " b'1461 KNC model AUC' b'1461 KNC no AUC' b'1461 LGBMC no AUC'\n",
      " b'1461 LR model ACC' b'1461 LR model F1' b'1461 LR no ACC'\n",
      " b'1461 LR no AUC' b'1461 SVC no ACC' b'1461 SVC no AUC' b'1461 SVC no F1'\n",
      " b'1463 DTC full ACC' b'1463 DTC full AUC' b'1463 DTC full F1'\n",
      " b'1463 DTC model AUC' b'1463 DTC model F1' b'1463 DTC no F1'\n",
      " b'1463 KNC model ACC' b'1463 KNC model AUC' b'1463 KNC no ACC'\n",
      " b'1463 KNC no AUC' b'1463 LGBMC no ACC' b'1463 LGBMC no F1'\n",
      " b'1463 LR full AUC' b'1463 LR full F1' b'1463 LR model F1'\n",
      " b'1463 LR no F1' b'1463 SVC full ACC' b'1463 SVC no ACC'\n",
      " b'1463 SVC no AUC' b'1463 SVC no F1' b'1486 DTC model AUC'\n",
      " b'1486 DTC no AUC' b'1486 DTC no F1' b'1486 KNC model ACC'\n",
      " b'1486 KNC model F1' b'1486 KNC no ACC' b'1486 KNC no AUC'\n",
      " b'1486 KNC no F1' b'1486 LGBMC no AUC' b'1486 LGBMC no F1'\n",
      " b'1486 LR model AUC' b'1486 LR no ACC' b'1486 SVC no ACC'\n",
      " b'1486 SVC no AUC' b'1506 DTC full ACC' b'1506 DTC full AUC'\n",
      " b'1506 DTC model F1' b'1506 DTC no ACC' b'1506 DTC no AUC'\n",
      " b'1506 KNC full ACC' b'1506 KNC full F1' b'1506 KNC model F1'\n",
      " b'1506 KNC no ACC' b'1506 LGBMC no AUC' b'1506 LR full AUC'\n",
      " b'1506 LR full F1' b'1506 LR model ACC' b'1506 LR model AUC'\n",
      " b'1506 LR model F1' b'1506 LR no ACC' b'1506 LR no AUC'\n",
      " b'1506 SVC full ACC' b'1506 SVC no ACC' b'1506 SVC no F1'\n",
      " b'1511 DTC full ACC' b'1511 DTC full AUC' b'1511 DTC model ACC'\n",
      " b'1511 KNC full ACC' b'1511 KNC full AUC' b'1511 KNC full F1'\n",
      " b'1511 KNC model F1' b'1511 KNC no ACC' b'1511 KNC no AUC'\n",
      " b'1511 LGBMC no ACC' b'1511 LGBMC no F1' b'1511 LR full ACC'\n",
      " b'1511 LR full AUC' b'1511 LR model ACC' b'1511 LR model AUC'\n",
      " b'1511 LR model F1' b'1511 LR no AUC' b'1511 LR no F1' b'1511 SVC no AUC'\n",
      " b'1511 SVC no F1' b'1590 DTC full AUC' b'1590 DTC full F1'\n",
      " b'1590 DTC model ACC' b'1590 DTC model AUC' b'1590 DTC model F1'\n",
      " b'1590 DTC no F1' b'1590 KNC full AUC' b'1590 KNC full F1'\n",
      " b'1590 KNC model ACC' b'1590 KNC model F1' b'1590 KNC no ACC'\n",
      " b'1590 LGBMC no ACC' b'1590 LGBMC no AUC' b'1590 LGBMC no F1'\n",
      " b'1590 LR full ACC' b'1590 LR full AUC' b'1590 LR model AUC'\n",
      " b'1590 LR model F1' b'1590 SVC no AUC' b'1590 SVC no F1'\n",
      " b'23381 DTC full ACC' b'23381 DTC full F1' b'23381 DTC model ACC'\n",
      " b'23381 DTC no AUC' b'23381 DTC no F1' b'23381 KNC full AUC'\n",
      " b'23381 KNC full F1' b'23381 KNC model ACC' b'23381 KNC model AUC'\n",
      " b'23381 KNC no ACC' b'23381 KNC no AUC' b'23381 KNC no F1'\n",
      " b'23381 LGBMC no ACC' b'23381 LGBMC no AUC' b'23381 LR full AUC'\n",
      " b'23381 LR full F1' b'23381 LR model ACC' b'23381 LR model F1'\n",
      " b'23381 LR no F1' b'23381 SVC no AUC' b'29 DTC full AUC'\n",
      " b'29 DTC full F1' b'29 DTC model AUC' b'29 DTC model F1' b'29 DTC no ACC'\n",
      " b'29 DTC no AUC' b'29 DTC no F1' b'29 KNC full AUC' b'29 KNC no ACC'\n",
      " b'29 LGBMC no ACC' b'29 LGBMC no F1' b'29 LR full ACC' b'29 LR full AUC'\n",
      " b'29 LR full F1' b'29 LR model F1' b'29 LR no F1' b'29 SVC full AUC'\n",
      " b'29 SVC no ACC' b'29 SVC no AUC' b'29 SVC no F1' b'3 DTC full ACC'\n",
      " b'3 DTC full F1' b'3 DTC model AUC' b'3 DTC model F1' b'3 KNC model AUC'\n",
      " b'3 KNC model F1' b'3 KNC no ACC' b'3 KNC no AUC' b'3 LGBMC no ACC'\n",
      " b'3 LGBMC no AUC' b'3 LR full ACC' b'3 LR full AUC' b'3 LR model ACC'\n",
      " b'3 LR model AUC' b'3 LR model F1' b'3 LR no ACC' b'3 LR no AUC'\n",
      " b'3 SVC full ACC' b'3 SVC no ACC' b'3 SVC no F1' b'31 DTC full F1'\n",
      " b'31 DTC model ACC' b'31 DTC model F1' b'31 DTC no AUC' b'31 DTC no F1'\n",
      " b'31 KNC full ACC' b'31 KNC model ACC' b'31 KNC model AUC'\n",
      " b'31 KNC model F1' b'31 KNC no F1' b'31 LGBMC no F1' b'31 LR full ACC'\n",
      " b'31 LR full AUC' b'31 LR model ACC' b'31 LR model AUC' b'31 LR model F1'\n",
      " b'31 LR no AUC' b'31 LR no F1' b'31 SVC full ACC' b'31 SVC no AUC'\n",
      " b'333 DTC full ACC' b'333 DTC full AUC' b'333 DTC full F1'\n",
      " b'333 DTC model ACC' b'333 DTC model AUC' b'333 DTC model F1'\n",
      " b'333 KNC full AUC' b'333 KNC model F1' b'333 KNC no ACC'\n",
      " b'333 KNC no F1' b'333 LR full ACC' b'333 LR full F1' b'333 LR model ACC'\n",
      " b'333 LR model AUC' b'333 LR model F1' b'333 LR no ACC'\n",
      " b'333 SVC full ACC' b'333 SVC full AUC' b'333 SVC no ACC'\n",
      " b'333 SVC no F1' b'334 DTC model ACC' b'334 DTC model F1'\n",
      " b'334 DTC no ACC' b'334 DTC no F1' b'334 KNC full F1'\n",
      " b'334 KNC model AUC' b'334 KNC no ACC' b'334 KNC no AUC'\n",
      " b'334 LGBMC no ACC' b'334 LGBMC no AUC' b'334 LGBMC no F1'\n",
      " b'334 LR full ACC' b'334 LR full AUC' b'334 LR model ACC'\n",
      " b'334 LR model AUC' b'334 LR model F1' b'334 LR no AUC' b'334 LR no F1'\n",
      " b'334 SVC no ACC' b'334 SVC no AUC' b'38 DTC full F1' b'38 DTC model ACC'\n",
      " b'38 KNC full ACC' b'38 KNC full AUC' b'38 KNC full F1'\n",
      " b'38 KNC model ACC' b'38 KNC model AUC' b'38 KNC model F1'\n",
      " b'38 KNC no AUC' b'38 KNC no F1' b'38 LGBMC no AUC' b'38 LGBMC no F1'\n",
      " b'38 LR full ACC' b'38 LR model ACC' b'38 LR model AUC' b'38 LR no ACC'\n",
      " b'38 LR no AUC' b'38 SVC full ACC' b'38 SVC full AUC' b'38 SVC no ACC'\n",
      " b'40536 DTC full F1' b'40536 DTC model ACC' b'40536 DTC model AUC'\n",
      " b'40536 DTC model F1' b'40536 DTC no ACC' b'40536 DTC no AUC'\n",
      " b'40536 KNC full ACC' b'40536 KNC full F1' b'40536 KNC no F1'\n",
      " b'40536 LGBMC no AUC' b'40536 LGBMC no F1' b'40536 LR full AUC'\n",
      " b'40536 LR full F1' b'40536 LR model ACC' b'40536 LR no ACC'\n",
      " b'40536 SVC full ACC' b'40536 SVC full AUC' b'40536 SVC full F1'\n",
      " b'40536 SVC no ACC' b'40536 SVC no AUC' b'40945 DTC model F1'\n",
      " b'40945 DTC no F1' b'40945 KNC model F1' b'40945 KNC no AUC'\n",
      " b'40945 KNC no F1' b'40945 LGBMC no AUC' b'40945 LGBMC no F1'\n",
      " b'40945 LR model ACC' b'40945 LR model F1' b'40945 LR no ACC'\n",
      " b'40945 LR no AUC' b'40945 LR no F1' b'40945 SVC no ACC'\n",
      " b'40945 SVC no F1' b'40981 DTC full ACC' b'40981 DTC full AUC'\n",
      " b'40981 DTC model AUC' b'40981 DTC model F1' b'40981 KNC full ACC'\n",
      " b'40981 KNC model ACC' b'40981 KNC model AUC' b'40981 KNC no F1'\n",
      " b'40981 LGBMC no AUC' b'40981 LGBMC no F1' b'40981 LR full ACC'\n",
      " b'40981 LR model ACC' b'40981 LR model AUC' b'40981 LR model F1'\n",
      " b'40981 LR no ACC' b'40981 LR no F1' b'40981 SVC full AUC'\n",
      " b'40981 SVC full F1' b'40981 SVC no ACC' b'40981 SVC no F1'\n",
      " b'40999 DTC full ACC' b'40999 DTC full F1' b'40999 DTC model AUC'\n",
      " b'40999 DTC no AUC' b'40999 KNC full AUC' b'40999 KNC full F1'\n",
      " b'40999 KNC model AUC' b'40999 KNC model F1' b'40999 KNC no F1'\n",
      " b'40999 LGBMC no AUC' b'40999 LGBMC no F1' b'40999 LR full ACC'\n",
      " b'40999 LR full F1' b'40999 LR model ACC' b'40999 LR no F1'\n",
      " b'40999 SVC full ACC' b'40999 SVC full AUC' b'40999 SVC full F1'\n",
      " b'40999 SVC no AUC' b'40999 SVC no F1' b'41005 DTC full AUC'\n",
      " b'41005 DTC model F1' b'41005 DTC no AUC' b'41005 DTC no F1'\n",
      " b'41005 KNC full ACC' b'41005 KNC full F1' b'41005 KNC model ACC'\n",
      " b'41005 KNC no ACC' b'41005 KNC no AUC' b'41005 LR full ACC'\n",
      " b'41005 LR full F1' b'41005 LR model AUC' b'41005 LR model F1'\n",
      " b'41005 LR no ACC' b'41005 LR no AUC' b'41005 LR no F1'\n",
      " b'41005 SVC full ACC' b'41005 SVC full F1' b'41005 SVC no AUC'\n",
      " b'41005 SVC no F1' b'41007 DTC full AUC' b'41007 DTC model ACC'\n",
      " b'41007 DTC model F1' b'41007 DTC no ACC' b'41007 DTC no AUC'\n",
      " b'41007 KNC full ACC' b'41007 KNC full AUC' b'41007 KNC model AUC'\n",
      " b'41007 KNC no ACC' b'41007 KNC no AUC' b'41007 KNC no F1'\n",
      " b'41007 LGBMC no AUC' b'41007 LGBMC no F1' b'41007 LR full AUC'\n",
      " b'41007 LR model AUC' b'41007 LR no F1' b'41007 SVC full F1'\n",
      " b'41007 SVC no ACC' b'41007 SVC no AUC' b'41007 SVC no F1'\n",
      " b'41162 DTC model ACC' b'41162 DTC model AUC' b'41162 DTC no ACC'\n",
      " b'41162 DTC no AUC' b'41162 DTC no F1' b'41162 KNC model AUC'\n",
      " b'41162 KNC model F1' b'41162 KNC no ACC' b'41162 KNC no AUC'\n",
      " b'41162 LGBMC no ACC' b'41162 LR model ACC' b'41162 LR model F1'\n",
      " b'41162 LR no AUC' b'41162 SVC no F1' b'41224 DTC model ACC'\n",
      " b'41224 KNC no ACC' b'41224 KNC no AUC' b'41224 KNC no F1'\n",
      " b'41224 LGBMC no ACC' b'41224 LGBMC no AUC' b'41224 LGBMC no F1'\n",
      " b'41224 LR model ACC' b'41224 LR model AUC' b'41224 LR no AUC'\n",
      " b'42178 DTC model F1' b'42178 DTC no ACC' b'42178 DTC no F1'\n",
      " b'42178 KNC model ACC' b'42178 KNC model AUC' b'42178 KNC model F1'\n",
      " b'42178 KNC no ACC' b'42178 LGBMC no ACC' b'42178 LGBMC no AUC'\n",
      " b'42178 LR model ACC' b'42178 LR model AUC' b'42178 LR no AUC'\n",
      " b'42178 LR no F1' b'42178 SVC no AUC' b'42343 DTC model ACC'\n",
      " b'42343 DTC no ACC' b'42343 DTC no AUC' b'42343 DTC no F1'\n",
      " b'42343 KNC model ACC' b'42343 KNC model F1' b'42343 KNC no ACC'\n",
      " b'42343 KNC no AUC' b'42343 LGBMC no ACC' b'42343 LGBMC no F1'\n",
      " b'42343 LR model AUC' b'42343 LR model F1' b'42343 SVC no ACC'\n",
      " b'42343 SVC no AUC' b'42344 DTC model ACC' b'42344 DTC model AUC'\n",
      " b'42344 DTC model F1' b'42344 DTC no ACC' b'42344 DTC no AUC'\n",
      " b'42344 KNC model F1' b'42344 KNC no AUC' b'42344 LGBMC no ACC'\n",
      " b'42344 LGBMC no AUC' b'42344 LR model ACC' b'42344 LR model AUC'\n",
      " b'42344 LR model F1' b'42344 LR no F1' b'42344 SVC no ACC'\n",
      " b'42738 DTC model ACC' b'42738 DTC model AUC' b'42738 DTC model F1'\n",
      " b'42738 DTC no ACC' b'42738 KNC model AUC' b'42738 KNC model F1'\n",
      " b'42738 KNC no ACC' b'42738 KNC no AUC' b'42738 LGBMC no ACC'\n",
      " b'42738 LGBMC no F1' b'42738 LR no ACC' b'42738 LR no AUC'\n",
      " b'42738 LR no F1' b'42738 SVC no ACC' b'42750 DTC model ACC'\n",
      " b'42750 DTC model AUC' b'42750 DTC model F1' b'42750 DTC no AUC'\n",
      " b'42750 KNC model AUC' b'42750 KNC model F1' b'42750 KNC no ACC'\n",
      " b'42750 LGBMC no AUC' b'42750 LR model ACC' b'42750 LR model AUC'\n",
      " b'42750 LR no ACC' b'42750 LR no F1' b'42750 SVC no AUC'\n",
      " b'42750 SVC no F1' b'43098 DTC model AUC' b'43098 DTC model F1'\n",
      " b'43098 DTC no ACC' b'43098 KNC full F1' b'43098 KNC model F1'\n",
      " b'43098 KNC no ACC' b'43098 KNC no AUC' b'43098 KNC no F1'\n",
      " b'43098 LGBMC no ACC' b'43098 LGBMC no AUC' b'43098 LR full AUC'\n",
      " b'43098 LR full F1' b'43098 LR model ACC' b'43098 LR model F1'\n",
      " b'43098 LR no ACC' b'43098 SVC full ACC' b'43098 SVC full AUC'\n",
      " b'43098 SVC no ACC' b'43098 SVC no AUC' b'43098 SVC no F1'\n",
      " b'43607 DTC model ACC' b'43607 DTC model AUC' b'43607 DTC no AUC'\n",
      " b'43607 DTC no F1' b'43607 KNC model F1' b'43607 KNC no ACC'\n",
      " b'43607 LGBMC no ACC' b'43607 LGBMC no F1' b'43607 LR model ACC'\n",
      " b'43607 LR model AUC' b'43607 LR no ACC' b'43607 LR no F1'\n",
      " b'43607 SVC no AUC' b'43607 SVC no F1' b'43890 DTC model ACC'\n",
      " b'43890 DTC no ACC' b'43890 DTC no F1' b'43890 KNC no ACC'\n",
      " b'43890 KNC no F1' b'43890 LR model ACC' b'43890 LR model AUC'\n",
      " b'43890 LR model F1' b'43890 LR no ACC' b'43890 LR no AUC'\n",
      " b'43890 SVC no ACC' b'43890 SVC no AUC' b'43890 SVC no F1'\n",
      " b'43892 DTC full AUC' b'43892 DTC model F1' b'43892 DTC no ACC'\n",
      " b'43892 DTC no AUC' b'43892 KNC full F1' b'43892 KNC model ACC'\n",
      " b'43892 KNC model AUC' b'43892 KNC model F1' b'43892 KNC no AUC'\n",
      " b'43892 KNC no F1' b'43892 LGBMC no ACC' b'43892 LGBMC no AUC'\n",
      " b'43892 LGBMC no F1' b'43892 LR full AUC' b'43892 LR model ACC'\n",
      " b'43892 LR model AUC' b'43892 SVC full AUC' b'43892 SVC full F1'\n",
      " b'43892 SVC no AUC' b'43892 SVC no F1' b'43896 DTC full ACC'\n",
      " b'43896 DTC full F1' b'43896 DTC model AUC' b'43896 DTC no ACC'\n",
      " b'43896 KNC full ACC' b'43896 KNC full F1' b'43896 KNC model ACC'\n",
      " b'43896 KNC model F1' b'43896 KNC no ACC' b'43896 KNC no F1'\n",
      " b'43896 LGBMC no AUC' b'43896 LR model ACC' b'43896 LR model AUC'\n",
      " b'43896 LR no ACC' b'43896 LR no AUC' b'43896 LR no F1'\n",
      " b'43896 SVC full ACC' b'43896 SVC full AUC' b'43896 SVC full F1'\n",
      " b'43896 SVC no ACC' b'43897 DTC full ACC' b'43897 DTC full F1'\n",
      " b'43897 DTC model ACC' b'43897 DTC no ACC' b'43897 KNC model AUC'\n",
      " b'43897 KNC model F1' b'43897 KNC no ACC' b'43897 KNC no F1'\n",
      " b'43897 LGBMC no F1' b'43897 LR full F1' b'43897 LR model ACC'\n",
      " b'43897 LR model AUC' b'43897 LR no AUC' b'43897 LR no F1'\n",
      " b'43897 SVC full ACC' b'43897 SVC full AUC' b'43897 SVC full F1'\n",
      " b'43897 SVC no ACC' b'43897 SVC no AUC' b'43897 SVC no F1'\n",
      " b'43900 DTC model ACC' b'43900 DTC model AUC' b'43900 DTC no ACC'\n",
      " b'43900 KNC model ACC' b'43900 KNC model AUC' b'43900 KNC model F1'\n",
      " b'43900 KNC no ACC' b'43900 KNC no AUC' b'43900 KNC no F1'\n",
      " b'43900 LR model AUC' b'43900 LR model F1' b'43900 LR no ACC'\n",
      " b'43900 LR no F1' b'43900 SVC no AUC' b'43922 DTC full ACC'\n",
      " b'43922 DTC full F1' b'43922 DTC model ACC' b'43922 DTC model F1'\n",
      " b'43922 DTC no F1' b'43922 KNC full AUC' b'43922 KNC model ACC'\n",
      " b'43922 KNC model AUC' b'43922 KNC model F1' b'43922 KNC no AUC'\n",
      " b'43922 LGBMC no ACC' b'43922 LGBMC no AUC' b'43922 LR full AUC'\n",
      " b'43922 LR full F1' b'43922 LR model ACC' b'43922 LR model F1'\n",
      " b'43922 LR no AUC' b'43922 LR no F1' b'43922 SVC full ACC'\n",
      " b'43922 SVC no AUC' b'451 DTC full ACC' b'451 DTC full AUC'\n",
      " b'451 DTC full F1' b'451 DTC model F1' b'451 DTC no ACC'\n",
      " b'451 DTC no AUC' b'451 DTC no F1' b'451 KNC full ACC' b'451 KNC full F1'\n",
      " b'451 KNC model F1' b'451 KNC no AUC' b'451 LGBMC no ACC'\n",
      " b'451 LGBMC no F1' b'451 LR full AUC' b'451 LR model ACC'\n",
      " b'451 LR model AUC' b'451 LR no ACC' b'451 LR no AUC' b'451 SVC no ACC'\n",
      " b'451 SVC no AUC' b'470 DTC full ACC' b'470 DTC model ACC'\n",
      " b'470 DTC no AUC' b'470 DTC no F1' b'470 KNC full AUC' b'470 KNC full F1'\n",
      " b'470 KNC model AUC' b'470 KNC model F1' b'470 KNC no ACC'\n",
      " b'470 KNC no AUC' b'470 KNC no F1' b'470 LGBMC no ACC'\n",
      " b'470 LGBMC no AUC' b'470 LR full AUC' b'470 LR full F1'\n",
      " b'470 LR model AUC' b'470 LR no AUC' b'470 SVC full ACC'\n",
      " b'470 SVC full F1' b'470 SVC no AUC' b'50 DTC full ACC'\n",
      " b'50 DTC full AUC' b'50 DTC full F1' b'50 DTC model AUC'\n",
      " b'50 DTC model F1' b'50 DTC no F1' b'50 KNC full AUC' b'50 KNC model ACC'\n",
      " b'50 KNC model AUC' b'50 KNC model F1' b'50 KNC no ACC' b'50 KNC no AUC'\n",
      " b'50 LGBMC no ACC' b'50 LR full AUC' b'50 LR full F1' b'50 LR no ACC'\n",
      " b'50 LR no F1' b'50 SVC full AUC' b'50 SVC full F1' b'50 SVC no ACC'\n",
      " b'51 DTC model ACC' b'51 DTC model AUC' b'51 DTC model F1'\n",
      " b'51 DTC no ACC' b'51 DTC no AUC' b'51 KNC model ACC' b'51 KNC model AUC'\n",
      " b'51 KNC model F1' b'51 LGBMC no ACC' b'51 LGBMC no AUC'\n",
      " b'51 LR model ACC' b'51 LR no ACC' b'51 SVC no ACC' b'51 SVC no AUC'\n",
      " b'56 DTC full AUC' b'56 DTC model AUC' b'56 DTC no AUC' b'56 DTC no F1'\n",
      " b'56 KNC full ACC' b'56 KNC full AUC' b'56 KNC full F1'\n",
      " b'56 KNC model F1' b'56 KNC no ACC' b'56 LGBMC no F1' b'56 LR full ACC'\n",
      " b'56 LR full AUC' b'56 LR full F1' b'56 LR model AUC' b'56 LR no ACC'\n",
      " b'56 LR no AUC' b'56 LR no F1' b'56 SVC full AUC' b'56 SVC no ACC'\n",
      " b'56 SVC no AUC' b'6332 DTC full ACC' b'6332 DTC full F1'\n",
      " b'6332 DTC model AUC' b'6332 DTC model F1' b'6332 DTC no ACC'\n",
      " b'6332 KNC full ACC' b'6332 KNC full AUC' b'6332 KNC full F1'\n",
      " b'6332 KNC model F1' b'6332 KNC no ACC' b'6332 KNC no AUC'\n",
      " b'6332 LGBMC no ACC' b'6332 LR full AUC' b'6332 LR model AUC'\n",
      " b'6332 LR no ACC' b'6332 LR no AUC' b'6332 LR no F1' b'6332 SVC full F1'\n",
      " b'6332 SVC no AUC' b'6332 SVC no F1' b'881 DTC full ACC'\n",
      " b'881 DTC full AUC' b'881 DTC model ACC' b'881 DTC model AUC'\n",
      " b'881 DTC no ACC' b'881 DTC no F1' b'881 KNC full F1'\n",
      " b'881 KNC model ACC' b'881 KNC model AUC' b'881 KNC model F1'\n",
      " b'881 KNC no F1' b'881 LGBMC no ACC' b'881 LR full ACC'\n",
      " b'881 LR full AUC' b'881 LR full F1' b'881 LR model AUC'\n",
      " b'881 LR model F1' b'881 SVC full ACC' b'881 SVC full AUC'\n",
      " b'881 SVC no F1' b'956 DTC full AUC' b'956 DTC full F1'\n",
      " b'956 DTC model ACC' b'956 DTC model F1' b'956 DTC no ACC'\n",
      " b'956 DTC no AUC' b'956 DTC no F1' b'956 KNC full AUC'\n",
      " b'956 KNC model ACC' b'956 KNC model AUC' b'956 KNC no ACC'\n",
      " b'956 KNC no AUC' b'956 KNC no F1' b'956 LR full ACC' b'956 LR full AUC'\n",
      " b'956 LR full F1' b'956 LR model AUC' b'956 LR no ACC'\n",
      " b'956 SVC full AUC' b'956 SVC full F1' b'959 DTC model ACC'\n",
      " b'959 DTC model AUC' b'959 DTC model F1' b'959 DTC no ACC'\n",
      " b'959 DTC no AUC' b'959 KNC model ACC' b'959 KNC model F1'\n",
      " b'959 KNC no AUC' b'959 KNC no F1' b'959 LGBMC no F1' b'959 LR model F1'\n",
      " b'959 LR no F1' b'959 SVC no ACC' b'959 SVC no AUC' b'981 DTC full ACC'\n",
      " b'981 DTC full AUC' b'981 DTC full F1' b'981 DTC model AUC'\n",
      " b'981 DTC no ACC' b'981 DTC no AUC' b'981 KNC full ACC'\n",
      " b'981 KNC full F1' b'981 KNC model F1' b'981 KNC no ACC'\n",
      " b'981 LGBMC no AUC' b'981 LR full AUC' b'981 LR model ACC'\n",
      " b'981 LR model F1' b'981 LR no AUC' b'981 LR no F1' b'981 SVC full AUC'\n",
      " b'981 SVC no ACC' b'981 SVC no AUC' b'981 SVC no F1']\n",
      "[b'BE' b'BUCV10RGLMME' b'BUCV10TE' b'BUCV2RGLMME' b'BUCV2TE'\n",
      " b'BUCV5RGLMME' b'BUCV5TE' b'CBE' b'CE' b'CV10RGLMME' b'CV10TE'\n",
      " b'CV2RGLMME' b'CV2TE' b'CV5RGLMME' b'CV5TE' b'DE' b'DTEM10' b'DTEM2'\n",
      " b'DTEM5' b'ME01E' b'ME10E' b'ME1E' b'MHE' b'OE' b'OHE' b'PBTE0001'\n",
      " b'PBTE001' b'PBTE01' b'RGLMME' b'SE' b'TE' b'WOEE']\n"
     ]
    }
   ],
   "source": [
    "# convert to a array containing all unique combinations of model, tuning, scoring as byte strings\n",
    "# unique_factor_combinations = np.unique(df_listwise[['model', 'tuning', 'scoring']])\n",
    "# unique_factor_combinations = unique_factor_combinations.astype('S')\n",
    "# print(unique_factor_combinations)\n",
    "\n",
    "# unique_model_combinations = np.unique(df_listwise['model'])\n",
    "# unique_model_combinations = unique_factor_combinations.astype('S')\n",
    "\n",
    "# unique_tuning_combinations = np.unique(df_listwise['tuning'])\n",
    "# unique_tuning_combinations = unique_factor_combinations.astype('S')\n",
    "\n",
    "unique_factor_combinations = np.unique(df[['features']])\n",
    "unique_factor_combinations = unique_factor_combinations.astype('S')\n",
    "print(unique_factor_combinations)\n",
    "\n",
    "unique_encoder_rankings = np.unique(df[['encoder']])\n",
    "unique_encoder_rankings = unique_encoder_rankings.astype('S')\n",
    "print(unique_encoder_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dict(inputs, fun=tf.stack):\n",
    "    values = []\n",
    "    for key in sorted(inputs.keys()):\n",
    "      values.append(tf.cast(inputs[key], tf.float32))\n",
    "\n",
    "    return fun(values, axis=-1)\n",
    "\n",
    "class RankingModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, loss):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "    # Compute embeddings for factor combinations.\n",
    "    self.factors_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_factor_combinations),\n",
    "      tf.keras.layers.Embedding(len(unique_factor_combinations) + 2, embedding_dimension)\n",
    "    ])\n",
    "    \n",
    "    # Compute embeddings for encoder combinations.\n",
    "    self.encoder_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_encoder_rankings),\n",
    "      tf.keras.layers.Embedding(len(unique_encoder_rankings) + 2, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.score_model = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "      loss=loss,\n",
    "      metrics=[\n",
    "        tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "        tf.keras.metrics.RootMeanSquaredError()\n",
    "      ]\n",
    "    )\n",
    "\n",
    "  def call(self, features):\n",
    "    # We first convert the id features into embeddings.\n",
    "    # User embeddings are a [batch_size, embedding_dim] tensor.\n",
    "    user_embeddings = self.factors_embeddings(features[\"features\"])\n",
    "\n",
    "    # Movie embeddings are a [batch_size, num_movies_in_list, embedding_dim]\n",
    "    # tensor.\n",
    "    movie_embeddings = self.encoder_embeddings(features[\"encoder\"])\n",
    "\n",
    "    # We want to concatenate user embeddings with movie emebeddings to pass\n",
    "    # them into the ranking model. To do so, we need to reshape the user\n",
    "    # embeddings to match the shape of movie embeddings.\n",
    "    #list_length = features[\"encoder\"].shape[1]\n",
    "    # get list length for my shape (10,) tensor\n",
    "    list_length = features[\"encoder\"].shape[1]\n",
    "    user_embedding_repeated = tf.repeat(\n",
    "        tf.expand_dims(user_embeddings, 1), [list_length], axis=1)\n",
    "\n",
    "    # Once reshaped, we concatenate and pass into the dense layers to generate\n",
    "    # predictions.\n",
    "    concatenated_embeddings = tf.concat(\n",
    "        [user_embedding_repeated, movie_embeddings], 2)\n",
    "\n",
    "    return self.score_model(concatenated_embeddings)\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    labels = features.pop(\"rank\")\n",
    "\n",
    "    scores = self(features)\n",
    "\n",
    "    return self.task(\n",
    "        labels=labels,\n",
    "        predictions=tf.squeeze(scores, axis=-1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss())\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 16ms/step - ndcg_metric: 0.5053 - root_mean_squared_error: 13.0832 - loss: 15.0967 - regularization_loss: 0.0000e+00 - total_loss: 15.0967\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 14ms/step - ndcg_metric: 0.5366 - root_mean_squared_error: 13.0869 - loss: 15.0771 - regularization_loss: 0.0000e+00 - total_loss: 15.0771\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 15ms/step - ndcg_metric: 0.5545 - root_mean_squared_error: 13.0774 - loss: 15.0496 - regularization_loss: 0.0000e+00 - total_loss: 15.0496\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 17ms/step - ndcg_metric: 0.5858 - root_mean_squared_error: 13.0672 - loss: 15.0090 - regularization_loss: 0.0000e+00 - total_loss: 15.0090\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 13ms/step - ndcg_metric: 0.5966 - root_mean_squared_error: 13.0468 - loss: 14.9693 - regularization_loss: 0.0000e+00 - total_loss: 14.9693\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - ndcg_metric: 0.5979 - root_mean_squared_error: 13.0304 - loss: 14.9432 - regularization_loss: 0.0000e+00 - total_loss: 14.9432\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - ndcg_metric: 0.6005 - root_mean_squared_error: 13.0112 - loss: 14.9187 - regularization_loss: 0.0000e+00 - total_loss: 14.9187\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - ndcg_metric: 0.6021 - root_mean_squared_error: 13.0098 - loss: 14.9192 - regularization_loss: 0.0000e+00 - total_loss: 14.9192\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - ndcg_metric: 0.6049 - root_mean_squared_error: 13.0087 - loss: 14.9073 - regularization_loss: 0.0000e+00 - total_loss: 14.9073\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - ndcg_metric: 0.6071 - root_mean_squared_error: 13.0070 - loss: 14.9017 - regularization_loss: 0.0000e+00 - total_loss: 14.9017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bddb7dd6d0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise_model.fit(cached_train, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - ndcg_metric: 0.6106 - root_mean_squared_error: 13.0102 - loss: 15.0119 - regularization_loss: 0.0000e+00 - total_loss: 15.0119\n",
      "NDCG of the MSE Model: 0.6106\n"
     ]
    }
   ],
   "source": [
    "listwise_model_result = listwise_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the MSE Model: {:.4f}\".format(listwise_model_result[\"ndcg_metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2890, 10, 1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = listwise_model.predict(cached_test)\n",
    "prediction.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
