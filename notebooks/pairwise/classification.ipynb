{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pandas as pd\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from datetime import timedelta\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from time import time\n",
    "\n",
    "from src import configuration as config\n",
    "from src.features.encoder_utils import NoY\n",
    "from src.pipeline.pipeline_factory import PipelineFactory, ModelType, EvaluationType\n",
    "from src.pipeline.pipeline_transformers import *\n",
    "\n",
    "\n",
    "# load the data\n",
    "df_train = config.load_traindata_for_pointwise()\n",
    "pipelineFactory = PipelineFactory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLEASE DELETE  \n",
    "Hier nur ein Beispiel wie man Optuna nutzen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-12 15:57:53,954] A new study created in memory with name: no-name-d6b6ef07-4b94-4f08-a791-eccf8bfd4740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pipeline ...\n",
      "[('dataset_transformer', OpenMLMetaFeatureTransformer(encoder=None, expected_pca_variance=0.6,\n",
      "                             nan_ratio_feature_drop_threshold=0.25)), ('general_transformer', GeneralPurposeEncoderTransformer(model_encoder=OneHotEncoder(),\n",
      "                                 scoring_encoder=OneHotEncoder(),\n",
      "                                 tuning_encoder=OneHotEncoder())), ('estimator', MultiOutputClassifier(estimator=DecisionTreeClassifier()))]\n",
      "Starting pipeline using method: EvaluationType.OPTUNA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb59244ef8304ba0bc195eeff6710c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [06:32<00:00, 78.43s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                    \n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                 \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-12 16:04:26,173] Trial 0 finished with value: 0.369 and parameters: {'general_transformer__model_encoder': 0, 'general_transformer__tuning_encoder': 0, 'general_transformer__scoring_encoder': 0, 'estimator__estimator__max_depth': 6}. Best is trial 0 with value: 0.369.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [06:35<00:00, 79.09s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                    \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                 \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-12 16:04:29,528] Trial 1 finished with value: 0.3691 and parameters: {'general_transformer__model_encoder': 1, 'general_transformer__tuning_encoder': 0, 'general_transformer__scoring_encoder': 1, 'estimator__estimator__max_depth': 10}. Best is trial 1 with value: 0.3691.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 5/5 [06:41<00:00, 80.25s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                 \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-12 16:04:35,317] Trial 2 finished with value: 0.3689 and parameters: {'general_transformer__model_encoder': 1, 'general_transformer__tuning_encoder': 0, 'general_transformer__scoring_encoder': 1, 'estimator__estimator__max_depth': 7}. Best is trial 1 with value: 0.3691.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [06:44<00:00, 80.88s/it]\n",
      "[I 2023-07-12 16:04:38,462] Trial 3 finished with value: 0.369 and parameters: {'general_transformer__model_encoder': 1, 'general_transformer__tuning_encoder': 0, 'general_transformer__scoring_encoder': 0, 'estimator__estimator__max_depth': 3}. Best is trial 1 with value: 0.3691.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m pipeline\u001b[39m.\u001b[39mchange_estimator(multi_dtc)\n\u001b[0;32m     33\u001b[0m \u001b[39mprint\u001b[39m(pipeline\u001b[39m.\u001b[39mget_pipeline()\u001b[39m.\u001b[39msteps)\n\u001b[1;32m---> 34\u001b[0m pipeline\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m     36\u001b[0m runtime \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(time() \u001b[39m-\u001b[39m start)\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mruntime: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(timedelta(seconds\u001b[39m=\u001b[39mruntime)) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m [\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(runtime) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39ms]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\marco\\workspace\\phase-2\\src\\pipeline\\model_pipeline.py:257\u001b[0m, in \u001b[0;36mModelPipeline.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validation_performance_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_bayes_search(\n\u001b[0;32m    246\u001b[0m         X_train,\n\u001b[0;32m    247\u001b[0m         y_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m         n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bayes_n_jobs\n\u001b[0;32m    254\u001b[0m     )\n\u001b[0;32m    256\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moptuna\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation \u001b[39m==\u001b[39m EvaluationType\u001b[39m.\u001b[39mOPTUNA:\n\u001b[1;32m--> 257\u001b[0m     study \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_optuna_search(param_grid\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_param_grid, cv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_folds, iterations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opt_iterations)\n\u001b[0;32m    259\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown evaluation type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\marco\\workspace\\phase-2\\src\\pipeline\\model_pipeline.py:729\u001b[0m, in \u001b[0;36mModelPipeline._do_optuna_search\u001b[1;34m(self, param_grid, cv, iterations)\u001b[0m\n\u001b[0;32m    727\u001b[0m show_progress_bar \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose_level \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    728\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 729\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49miterations, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar)\n\u001b[0;32m    731\u001b[0m \u001b[39mreturn\u001b[39;00m study\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:85\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     82\u001b[0m time_start \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m     83\u001b[0m futures: Set[Future] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m---> 85\u001b[0m \u001b[39mwith\u001b[39;49;00m ThreadPoolExecutor(max_workers\u001b[39m=\u001b[39;49mn_jobs) \u001b[39mas\u001b[39;49;00m executor:\n\u001b[0;32m     86\u001b[0m     \u001b[39mfor\u001b[39;49;00m n_submitted_trials \u001b[39min\u001b[39;49;00m itertools\u001b[39m.\u001b[39;49mcount():\n\u001b[0;32m     87\u001b[0m         \u001b[39mif\u001b[39;49;00m study\u001b[39m.\u001b[39;49m_stop_flag:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m--> 647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    648\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[1;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"general_transformer__model_encoder\" : [BinaryEncoder(), OneHotEncoder()],\n",
    "    \"general_transformer__tuning_encoder\" : [BinaryEncoder()],\n",
    "    \"general_transformer__scoring_encoder\" : [BinaryEncoder(), OneHotEncoder()],\n",
    "    \"estimator__estimator__max_depth\" : [2, 10], # IMPORTANT only use 2 values here. These values represent the range optuna is using to search for the best parameter. So all values between 2 and 10 in this case.\n",
    "}\n",
    "\n",
    "start = time()\n",
    "df_train = config.load_traindata_for_pointwise()\n",
    "pipeline = pipelineFactory.create_pipeline(\n",
    "    train_df=df_train,\n",
    "    model_type=ModelType.PAIRWISE_CLASSIFICATION_NO_SEARCH,\n",
    "    verbose_level=1,\n",
    "    evaluation=EvaluationType.OPTUNA,\n",
    "    n_folds=2,\n",
    "    workers=1,\n",
    "    target=\"rank\",\n",
    "    as_pairwise=True,\n",
    "    param_grid=param_grid,\n",
    "    opt_iterations=4 # The number of iterations optuna should use to find the best hyperparameters\n",
    ")\n",
    "#set_baseline_steps(pipeline)\n",
    "\n",
    "# create a decision tree classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "# create a multi-output classifier using the decision tree\n",
    "multi_dtc = MultiOutputClassifier(dtc)\n",
    "pipeline.change_estimator(multi_dtc)\n",
    "\n",
    "print(pipeline.get_pipeline().steps)\n",
    "pipeline.run()\n",
    "\n",
    "runtime = int(time() - start)\n",
    "print('\\nruntime: ' + str(timedelta(seconds=runtime)) + ' [' + str(runtime) + 's]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
