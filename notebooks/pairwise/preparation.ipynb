{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (27040, 7)\n",
      "df_test shape: (9014, 7)\n",
      "       dataset model tuning scoring     encoder  cv_score  rank\n",
      "22557       29   DTC   full     AUC  CV10RGLMME  0.837250   0.0\n",
      "18217    40981    LR     no      F1          CE  0.780664  28.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import configuration as config\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR = config.DATA_RAW_DIR\n",
    "\n",
    "df_train = config.load_dataset(DATA_DIR / \"dataset_rank_train.csv\")\n",
    "# split the data\n",
    "df_train, df_test = train_test_split(df_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# print the shape of the data\n",
    "print(f\"df_train shape: {df_train.shape}\")\n",
    "print(f\"df_test shape: {df_test.shape}\")\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['dataset', 'model', 'tuning', 'scoring']\n",
    "new_index =  ['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (27040, 7)\n",
      "Initial df_train: \n",
      "        dataset model tuning scoring     encoder  cv_score  rank\n",
      "22557       29   DTC   full     AUC  CV10RGLMME  0.837250   0.0\n",
      "18217    40981    LR     no      F1          CE  0.780664  28.0\n",
      "After the groupby: \n",
      "        dataset model tuning scoring     encoder\n",
      "22557       29   DTC   full     AUC  CV10RGLMME\n",
      "18217    40981    LR     no      F1          CE\n",
      "21858      981    LR     no      F1       CV2TE\n",
      "13962     1169   DTC  model      F1     BUCV2TE\n",
      "1680     40981   DTC  model     AUC        ME1E\n",
      "...        ...   ...    ...     ...         ...\n",
      "17699    42344   SVC     no     ACC         CBE\n",
      "3767     42343   KNC  model     AUC          TE\n",
      "1137     42750   KNC  model      F1       DTEM5\n",
      "13089    42344   SVC     no      F1         CBE\n",
      "17130    42343   SVC     no     ACC          OE\n",
      "\n",
      "[2317 rows x 5 columns]\n",
      "Before the reset:\n",
      "                               encoder\n",
      "dataset model tuning scoring         \n",
      "3       DTC   full   ACC          NaN\n",
      "                     AUC          NaN\n",
      "aggregated_train shape: (1160, 1)\n",
      "After the reset:\n",
      "    dataset model tuning scoring\n",
      "0        3   DTC   full     ACC\n",
      "1        3   DTC   full     AUC\n",
      "X_train shape: (1160, 4)\n"
     ]
    }
   ],
   "source": [
    "# Here we essentially remove all the encoders and make sure that the factors are unique meaning that we have no duplicates\n",
    "\n",
    "print(f\"df_train shape: {df_train.shape}\")\n",
    "print(f\"Initial df_train: \\n {df_train.head(2)}\")\n",
    "\n",
    "# Select the factors and encoder columns from the training data and group by the factors\n",
    "grouped_train = df_train[factors + [\"encoder\"]].groupby(factors)\n",
    "print(f\"After the groupby: \\n {grouped_train.head(2)}\")\n",
    "\n",
    "# Aggregate the grouped data by replacing all values with NaN\n",
    "aggregated_train = grouped_train.agg(lambda x: np.nan)\n",
    "print(f\"Before the reset:\\n {aggregated_train.head(2)}\")\n",
    "print(f\"aggregated_train shape: {aggregated_train.shape}\")\n",
    "\n",
    "# Reset the index of the aggregated data to make the factors columns regular columns\n",
    "X_train = aggregated_train.reset_index()[factors]\n",
    "print(f\"After the reset:\\n {X_train.head(2)}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "# Do the same for the test data\n",
    "grouped_test = df_test[factors + [\"encoder\"]].groupby(factors)\n",
    "aggregated_test = grouped_test.agg(lambda x: np.nan)\n",
    "X_test = aggregated_test.reset_index()[factors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import pairwise_utils as pu\n",
    "\n",
    "# join to ensure X_train and y_train's indices are ordered the same\n",
    "y_train = pd.merge(X_train,\n",
    "                   pu.get_pairwise_target(df_train, features=factors, target=\"rank\", column_to_compare=\"encoder\"),\n",
    "                   on=factors, how=\"left\").drop(factors, axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1160, 4)\n",
      "y_train shape: (1160, 992)\n",
      "y_train: \n",
      "    (CV10RGLMME, CV2TE)  (CV2TE, CV10RGLMME)  (CV10RGLMME, ME1E)  \\\n",
      "0                  0.0                  0.0                 0.0   \n",
      "1                  0.0                  0.0                 0.0   \n",
      "\n",
      "   (ME1E, CV10RGLMME)  (CV10RGLMME, PBTE01)  (PBTE01, CV10RGLMME)  \\\n",
      "0                 0.0                   1.0                   0.0   \n",
      "1                 0.0                   1.0                   0.0   \n",
      "\n",
      "   (CV10RGLMME, DTEM5)  (DTEM5, CV10RGLMME)  (CV10RGLMME, CV10TE)  \\\n",
      "0                  0.0                  0.0                   0.0   \n",
      "1                  0.0                  0.0                   0.0   \n",
      "\n",
      "   (CV10TE, CV10RGLMME)  ...  (BUCV5RGLMME, DTEM2)  (DTEM2, BUCV5RGLMME)  \\\n",
      "0                   0.0  ...                   0.0                   0.0   \n",
      "1                   0.0  ...                   0.0                   0.0   \n",
      "\n",
      "   (BUCV5RGLMME, PBTE0001)  (PBTE0001, BUCV5RGLMME)  (BUCV5RGLMME, CBE)  \\\n",
      "0                      0.0                      0.0                 1.0   \n",
      "1                      0.0                      0.0                 0.0   \n",
      "\n",
      "   (CBE, BUCV5RGLMME)  (BUCV5RGLMME, CV2RGLMME)  (CV2RGLMME, BUCV5RGLMME)  \\\n",
      "0                 0.0                       0.0                       0.0   \n",
      "1                 0.0                       0.0                       0.0   \n",
      "\n",
      "   (BUCV5RGLMME, DTEM10)  (DTEM10, BUCV5RGLMME)  \n",
      "0                    0.0                    0.0  \n",
      "1                    0.0                    0.0  \n",
      "\n",
      "[2 rows x 992 columns]\n"
     ]
    }
   ],
   "source": [
    "# shape of y_train\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_train: \\n {y_train.head(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\scipy\\stats\\_mstats_basic.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  t = rs * np.sqrt((dof / ((rs+1.0) * (1.0-rs))).clip(0))\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\scipy\\stats\\_mstats_basic.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  t = rs * np.sqrt((dof / ((rs+1.0) * (1.0-rs))).clip(0))\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\scipy\\stats\\_mstats_basic.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  t = rs * np.sqrt((dof / ((rs+1.0) * (1.0-rs))).clip(0))\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\scipy\\stats\\_mstats_basic.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  t = rs * np.sqrt((dof / ((rs+1.0) * (1.0-rs))).clip(0))\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\scipy\\stats\\_mstats_basic.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  t = rs * np.sqrt((dof / ((rs+1.0) * (1.0-rs))).clip(0))\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\scipy\\stats\\_mstats_basic.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  t = rs * np.sqrt((dof / ((rs+1.0) * (1.0-rs))).clip(0))\n",
      "c:\\Users\\Marco\\Workspace\\phase-2\\venv\\Lib\\site-packages\\scipy\\stats\\_mstats_basic.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  t = rs * np.sqrt((dof / ((rs+1.0) * (1.0-rs))).clip(0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00038541406487959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# import mutli output random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from category_encoders import OneHotEncoder\n",
    "from src.features import encoder_utils as eu\n",
    "import src.pipeline.evaluation.evaluation_utils as er\n",
    "\n",
    "# create a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# create a multi-output classifier using the random forest\n",
    "multi_rf = MultiOutputClassifier(rf)\n",
    "\n",
    "dummy_pipe = Pipeline([(\"encoder\", eu.NoY(OneHotEncoder())), (\"model\", multi_rf)])\n",
    "y_pred = pd.DataFrame(dummy_pipe.fit(X_train, y_train).predict(X_test), columns=y_train.columns, index=X_test.index)\n",
    "df_pred = pd.merge(df_test,\n",
    "                   pu.join_pairwise2rankings(X_test, y_pred, factors),\n",
    "                   on=factors + [\"encoder\"], how=\"inner\")\n",
    "\n",
    "rankings_test = er.get_rankings(df_pred, factors=factors, new_index=new_index, target=\"rank\")\n",
    "rankings_pred = er.get_rankings(df_pred, factors=factors, new_index=new_index, target=\"rank_pred\")\n",
    "print(er.average_spearman(rankings_test, rankings_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
